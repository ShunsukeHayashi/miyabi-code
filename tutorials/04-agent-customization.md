# Tutorial 4: Agent Customization - Building Your Own Prompts

**Estimated Time**: 60 minutes
**Difficulty**: â­â­ Intermediate
**Prerequisites**: Completed Tutorials 1-3, YAML/Markdown familiarity, Basic understanding of LLM prompting

## Learning Objectives

By the end of this tutorial, you will:
- Understand Agent spec file structure and key components
- Customize existing Agent prompts for specific workflows
- Configure Agent parameters via `miyabi.toml`
- Override default Agent behaviors safely
- Test and validate custom Agents before deployment

## Prerequisites

Before starting, ensure you have:
- **Completed Beginner Tutorials**: Tutorials 1-3 are essential
- **Text Editor**: VS Code, Vim, or any editor with YAML/Markdown syntax highlighting
- **LLM Prompting Knowledge**: Basic understanding of how to write effective AI prompts
- **Running Miyabi Installation**: Able to execute `miyabi agent run` commands

## Introduction

Miyabi's power lies in its 21 autonomous Agents, but one size doesn't fit all. Different teams have different coding standards, documentation styles, and workflows. That's where Agent customization comes in.

In this tutorial, you'll learn how to customize Agents to match your team's unique requirements. You'll modify CodeGenAgent to follow a specific coding style, adjust ReviewAgent's scoring criteria, and configure Agents to use different LLM backends.

By the end, you'll have a customized Miyabi setup that feels like it was built specifically for your team.

## Agent Spec Files Overview

Every Miyabi Agent is defined by two key files:
1. **Agent Spec** (`.claude/agents/specs/coding/*.md` or `.../business/*.md`)
2. **Agent Prompt** (`.claude/agents/prompts/coding/*.md`)

### Location and Structure

```bash
.claude/agents/
â”œâ”€â”€ specs/
â”‚   â”œâ”€â”€ coding/
â”‚   â”‚   â”œâ”€â”€ coordinator-agent.md
â”‚   â”‚   â”œâ”€â”€ codegen-agent.md
â”‚   â”‚   â”œâ”€â”€ review-agent.md
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ business/
â”‚       â”œâ”€â”€ ai-entrepreneur-agent.md
â”‚       â”œâ”€â”€ content-creation-agent.md
â”‚       â””â”€â”€ ...
â””â”€â”€ prompts/
    â””â”€â”€ coding/
        â”œâ”€â”€ codegen-agent-prompt.md
        â”œâ”€â”€ review-agent-prompt.md
        â””â”€â”€ ...
```

### Agent Spec Anatomy

Let's examine the structure of a typical Agent spec file. Here's a simplified version of `codegen-agent.md`:

```yaml
---
name: CodeGenAgent
description: AIé§†å‹•ã‚³ãƒ¼ãƒ‰ç”ŸæˆAgent - Claude Sonnet 4ã«ã‚ˆã‚‹è‡ªå‹•ã‚³ãƒ¼ãƒ‰ç”Ÿæˆ
authority: ğŸ”µå®Ÿè¡Œæ¨©é™
escalation: TechLead (ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å•é¡Œæ™‚)
---

# CodeGenAgent - AIé§†å‹•ã‚³ãƒ¼ãƒ‰ç”ŸæˆAgent

## å½¹å‰²
GitHub Issueã®å†…å®¹ã‚’è§£æã—ã€Claude Sonnet 4 APIã‚’ä½¿ç”¨ã—ã¦å¿…è¦ãªã‚³ãƒ¼ãƒ‰å®Ÿè£…ã‚’è‡ªå‹•ç”Ÿæˆã—ã¾ã™ã€‚

## è²¬ä»»ç¯„å›²
- Issueå†…å®¹ã®ç†è§£ã¨è¦ä»¶æŠ½å‡º
- Rustã‚³ãƒ¼ãƒ‰è‡ªå‹•ç”Ÿæˆï¼ˆRust 2021 Editionã€Clippyæº–æ‹ ï¼‰
- ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆè‡ªå‹•ç”Ÿæˆ
- å‹å®šç¾©ã®è¿½åŠ 
- Rustdocã‚³ãƒ¡ãƒ³ãƒˆã®ç”Ÿæˆ

## å®Ÿè¡Œæ¨©é™
ğŸ”µ **å®Ÿè¡Œæ¨©é™**: ã‚³ãƒ¼ãƒ‰ç”Ÿæˆã‚’ç›´æ¥å®Ÿè¡Œå¯èƒ½ï¼ˆReviewAgentæ¤œè¨¼å¾Œã«ãƒãƒ¼ã‚¸ï¼‰

## æˆåŠŸæ¡ä»¶
âœ… **å¿…é ˆæ¡ä»¶**:
- ã‚³ãƒ¼ãƒ‰ãŒ`cargo build`æˆåŠŸã™ã‚‹
- `cargo clippy`è­¦å‘Š0ä»¶
- `cargo test`ãŒãƒ‘ã‚¹ã™ã‚‹
- åŸºæœ¬çš„ãªãƒ†ã‚¹ãƒˆãŒç”Ÿæˆã•ã‚Œã‚‹
```

**Key Sections**:
- **YAML Frontmatter**: Metadata about the Agent (name, authority, escalation rules)
- **å½¹å‰² (Role)**: High-level description of the Agent's purpose
- **è²¬ä»»ç¯„å›² (Responsibilities)**: Specific tasks the Agent handles
- **å®Ÿè¡Œæ¨©é™ (Execution Authority)**: What the Agent can do autonomously
- **æˆåŠŸæ¡ä»¶ (Success Criteria)**: Measurable outcomes to verify completion

### Agent Prompt Anatomy

Agent prompts are Markdown files containing step-by-step instructions for execution within a Git Worktree. Example from `codegen-agent-prompt.md`:

```markdown
# CodeGenAgent - Worktreeå®Ÿè¡Œãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ

ã‚ãªãŸã¯CodeGenAgentï¼ˆã¤ãã‚‹ã‚“ï¼‰ã§ã™ã€‚ã“ã®Worktreeå†…ã§Issueã«å¯¾å¿œã™ã‚‹ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè£…ã—ã¦ãã ã•ã„ã€‚

## Step 1: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç†è§£
`EXECUTION_CONTEXT.md`ã‚’èª­ã¿ã€Issueå†…å®¹ã¨Taskã®è©³ç´°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚

## Step 2: æ—¢å­˜ã‚³ãƒ¼ãƒ‰åˆ†æ
é–¢é€£ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’`Read`ãƒ„ãƒ¼ãƒ«ã§èª­ã¿è¾¼ã¿ã€æ—¢å­˜ã®å®Ÿè£…ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç†è§£ã—ã¦ãã ã•ã„ã€‚

## Step 3: ã‚³ãƒ¼ãƒ‰ç”Ÿæˆ
Rust 2021 Editionã«æº–æ‹ ã—ã€ä»¥ä¸‹ã‚’æº€ãŸã™ã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„:
- Clippyæº–æ‹ ï¼ˆ32 lintså¯¾å¿œï¼‰
- ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆï¼ˆ`#[tokio::test]`ï¼‰
- Rustdocã‚³ãƒ¡ãƒ³ãƒˆï¼ˆ`///`ï¼‰

## Step 4: ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
```bash
cargo test --package [your-crate]
cargo clippy
```

## Step 5: ã‚³ãƒŸãƒƒãƒˆ
Conventional Commitså½¢å¼ã§ã‚³ãƒŸãƒƒãƒˆã—ã¦ãã ã•ã„ã€‚
```

**Key Elements**:
- **Context Injection**: References to `EXECUTION_CONTEXT.md` and `.agent-context.json`
- **Step-by-Step Instructions**: Clear, actionable steps
- **Code Examples**: Runnable commands and code snippets
- **Quality Gates**: Testing and validation requirements

## Customizing Existing Agents

Now let's customize CodeGenAgent to enforce a specific coding style.

### Scenario: Enforce Custom Error Handling

Your team uses a custom error handling pattern with `thiserror` and specific error message formats. Let's customize CodeGenAgent to enforce this.

### Step 1: Copy the Original Spec

**Best Practice**: Never modify original specs directly. Create a custom version.

```bash
cd /Users/shunsuke/Dev/miyabi-private
cp .claude/agents/specs/coding/codegen-agent.md \
   .claude/agents/specs/coding/codegen-agent-custom.md
```

### Step 2: Modify the Spec

Edit `.claude/agents/specs/coding/codegen-agent-custom.md`:

```yaml
---
name: CodeGenAgent
description: AIé§†å‹•ã‚³ãƒ¼ãƒ‰ç”ŸæˆAgent - ã‚«ã‚¹ã‚¿ãƒ ã‚¨ãƒ©ãƒ¼å‡¦ç†ãƒ‘ã‚¿ãƒ¼ãƒ³é©ç”¨ç‰ˆ
authority: ğŸ”µå®Ÿè¡Œæ¨©é™
escalation: TechLead (ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å•é¡Œæ™‚)
custom_rules:
  error_handling: thiserror
  error_format: "Context-first format"
---

# CodeGenAgent - ã‚«ã‚¹ã‚¿ãƒ ç‰ˆ

## å½¹å‰²
ï¼ˆæ—¢å­˜ã®å½¹å‰²ã‚’ç¶­æŒï¼‰

## è²¬ä»»ç¯„å›²
ï¼ˆæ—¢å­˜ã®è²¬ä»»ç¯„å›²ã«åŠ ãˆã¦ï¼‰

- **ã‚«ã‚¹ã‚¿ãƒ ã‚¨ãƒ©ãƒ¼å‡¦ç†**:
  - `thiserror` crateä½¿ç”¨å¿…é ˆ
  - ã‚¨ãƒ©ãƒ¼å‹ã¯`{Feature}Error`å‘½åè¦å‰‡
  - Context-first error messages: `Failed to {action}: {reason}`

## ã‚³ãƒ¼ãƒ‰ç”Ÿæˆè¦å‰‡

### ã‚¨ãƒ©ãƒ¼å‡¦ç†ãƒ‘ã‚¿ãƒ¼ãƒ³

ã™ã¹ã¦ã®ã‚¨ãƒ©ãƒ¼ã¯ä»¥ä¸‹ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã«å¾“ã†:

```rust
use thiserror::Error;

#[derive(Debug, Error)]
pub enum MyFeatureError {
    #[error("Failed to execute task: {reason}")]
    ExecutionError { reason: String },

    #[error("Failed to read file {path}: {source}")]
    FileReadError {
        path: String,
        #[source]
        source: std::io::Error,
    },
}
```

### ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ

ã™ã¹ã¦ã®ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯ **Context-first** å½¢å¼:
- âœ… "Failed to connect to database: connection timeout"
- âŒ "Connection timeout: database connection failed"

## æˆåŠŸæ¡ä»¶

âœ… **å¿…é ˆæ¡ä»¶**ï¼ˆæ—¢å­˜ã«åŠ ãˆã¦ï¼‰:
- ã™ã¹ã¦ã®ã‚¨ãƒ©ãƒ¼å‹ãŒ`thiserror`ã‚’ä½¿ç”¨
- ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒContext-firstå½¢å¼
- ã‚¨ãƒ©ãƒ¼å‹å‘½åè¦å‰‡ã«æº–æ‹ 
```

### Step 3: Update the Agent Prompt

Edit `.claude/agents/prompts/coding/codegen-agent-prompt-custom.md`:

```markdown
# CodeGenAgent - ã‚«ã‚¹ã‚¿ãƒ ã‚¨ãƒ©ãƒ¼å‡¦ç†ç‰ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ

ï¼ˆæ—¢å­˜ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å†…å®¹ï¼‰

## Step 3: ã‚³ãƒ¼ãƒ‰ç”Ÿæˆï¼ˆã‚«ã‚¹ã‚¿ãƒ ç‰ˆï¼‰

### ã‚¨ãƒ©ãƒ¼å‡¦ç†å®Ÿè£…

**å¿…é ˆãƒ«ãƒ¼ãƒ«**:
1. ã™ã¹ã¦ã®ã‚¨ãƒ©ãƒ¼ã¯`thiserror::Error`ã‚’ä½¿ç”¨
2. ã‚¨ãƒ©ãƒ¼å‹å‘½å: `{Feature}Error`
3. ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: `Failed to {action}: {reason}`

**å®Ÿè£…ä¾‹**:

```rust
use thiserror::Error;

#[derive(Debug, Error)]
pub enum AgentError {
    #[error("Failed to execute agent task: {reason}")]
    ExecutionError { reason: String },

    #[error("Failed to parse config at {path}: {source}")]
    ConfigParseError {
        path: String,
        #[source]
        source: serde_json::Error,
    },
}

// ä½¿ç”¨ä¾‹
fn execute_task() -> Result<(), AgentError> {
    let config = read_config().map_err(|e| AgentError::ExecutionError {
        reason: format!("Failed to read config: {}", e),
    })?;
    Ok(())
}
```

## Step 4: æ¤œè¨¼

ã‚«ã‚¹ã‚¿ãƒ ãƒ«ãƒ¼ãƒ«ã«æº–æ‹ ã—ã¦ã„ã‚‹ã‹ç¢ºèª:

```bash
# ã‚¨ãƒ©ãƒ¼å‹ã®å‘½åè¦å‰‡ãƒã‚§ãƒƒã‚¯
rg "enum \w+Error" --type rust

# thiserrorä½¿ç”¨ãƒã‚§ãƒƒã‚¯
rg "derive.*Error" --type rust

# ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆãƒã‚§ãƒƒã‚¯
rg 'error\("Failed to' --type rust
```
```

### Step 4: Configure Miyabi to Use Custom Spec

Edit `miyabi.toml` (or create it if it doesn't exist):

```toml
[agents.codegen]
spec_path = ".claude/agents/specs/coding/codegen-agent-custom.md"
prompt_path = ".claude/agents/prompts/coding/codegen-agent-prompt-custom.md"
enabled = true

# Optional: Override LLM settings
[agents.codegen.llm]
model = "claude-sonnet-4-20250514"
max_tokens = 8000
reasoning_effort = "medium"  # low, medium, high
```

## Creating Custom Agent Prompts

Effective prompts are the key to Agent success. Let's explore prompt engineering best practices for Miyabi Agents.

### Prompt Engineering Principles

#### 1. Be Specific and Actionable

**Bad Prompt**:
```
Generate some code for the Issue.
```

**Good Prompt**:
```
Generate Rust code that implements the Issue requirements. Ensure:
1. Code compiles with `cargo build`
2. All tests pass with `cargo test`
3. Clippy warnings are resolved
4. Code follows project style guide
```

#### 2. Provide Context

Always reference the Worktree context files:

```markdown
## Step 1: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç†è§£

ä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€å®Ÿè¡Œã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ç†è§£ã—ã¦ãã ã•ã„:

1. **EXECUTION_CONTEXT.md**: Issueæƒ…å ±ã€Taskè©³ç´°ã€Worktreeãƒ‘ã‚¹
2. **.agent-context.json**: æ©Ÿæ¢°å¯èª­ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼ˆAgentè¨­å®šã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ‘ã‚¹ï¼‰

```bash
# ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç¢ºèª
cat EXECUTION_CONTEXT.md
cat .agent-context.json
```
```

#### 3. Include Examples

Examples are worth a thousand words:

```markdown
## Step 3: ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆç”Ÿæˆ

ã™ã¹ã¦ã®å…¬é–‹é–¢æ•°ã«å¯¾ã—ã¦ãƒ†ã‚¹ãƒˆã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

**ãƒ†ã‚¹ãƒˆä¾‹**:

```rust
#[cfg(test)]
mod tests {
    use super::*;

    #[tokio::test]
    async fn test_execute_task_success() {
        let agent = CoordinatorAgent::new(Config::default());
        let task = Task::new("test-task", TaskType::Analysis);

        let result = agent.execute(&task).await;

        assert!(result.is_ok());
    }

    #[tokio::test]
    async fn test_execute_task_invalid_input() {
        let agent = CoordinatorAgent::new(Config::default());
        let task = Task::new("", TaskType::Analysis);

        let result = agent.execute(&task).await;

        assert!(result.is_err());
    }
}
```
```

#### 4. Define Clear Success Criteria

```markdown
## æˆåŠŸãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

å®Ÿè£…å®Œäº†å‰ã«ä»¥ä¸‹ã‚’ç¢ºèªã—ã¦ãã ã•ã„:

- [ ] `cargo build` ãŒæˆåŠŸã™ã‚‹
- [ ] `cargo test` ãŒå…¨ã¦ãƒ‘ã‚¹ã™ã‚‹
- [ ] `cargo clippy` ãŒè­¦å‘Š0ä»¶
- [ ] ã‚«ã‚¹ã‚¿ãƒ ã‚¨ãƒ©ãƒ¼å‡¦ç†ãƒ«ãƒ¼ãƒ«ã«æº–æ‹ 
- [ ] å…¨ã¦ã®å…¬é–‹é–¢æ•°ã«Rustdocã‚³ãƒ¡ãƒ³ãƒˆ
- [ ] `EXECUTION_CONTEXT.md` ã«æˆæœç‰©ãƒ‘ã‚¹ã‚’è¨˜è¼‰
```

#### 5. Output Formatting

Specify how the Agent should report results:

```markdown
## Step 5: çµæœãƒ¬ãƒãƒ¼ãƒˆ

`EXECUTION_CONTEXT.md`ã«ä»¥ä¸‹ã®å½¢å¼ã§çµæœã‚’è¿½è¨˜ã—ã¦ãã ã•ã„:

```markdown
## å®Ÿè¡Œçµæœ

**Generated Files**:
- `crates/miyabi-agents/src/my_feature.rs` (124 lines)
- `crates/miyabi-agents/tests/my_feature_test.rs` (56 lines)

**Test Results**:
```
cargo test
   Running tests (target/debug/deps/miyabi_agents-xxx)
running 3 tests
test tests::test_my_feature ... ok
test tests::test_error_handling ... ok
test tests::test_edge_cases ... ok

test result: ok. 3 passed; 0 failed
```

**Quality Metrics**:
- Lines of Code: 180
- Test Coverage: 85%
- Clippy Warnings: 0
```
```

### Real-World Example: Custom ReviewAgent Prompt

Let's create a custom ReviewAgent prompt that focuses on security best practices.

**File**: `.claude/agents/prompts/coding/review-agent-prompt-security.md`

```markdown
# ReviewAgent - ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£é‡è¦–ç‰ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ

ã‚ãªãŸã¯ReviewAgentï¼ˆã‚ã ã¾ã‚“ï¼‰ã§ã™ã€‚ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã«ç‰¹åŒ–ã—ã¦ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’å®Ÿæ–½ã—ã¦ãã ã•ã„ã€‚

## Step 1: ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

ä»¥ä¸‹ã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒªã‚¹ã‚¯ã‚’é‡ç‚¹çš„ã«ç¢ºèª:

### 1. å…¥åŠ›ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
- [ ] ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã¯å…¨ã¦ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³æ¸ˆã¿
- [ ] SQLã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³å¯¾ç­–ï¼ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒ–ã‚¯ã‚¨ãƒªä½¿ç”¨ï¼‰
- [ ] ãƒ‘ã‚¹ãƒˆãƒ©ãƒãƒ¼ã‚µãƒ«å¯¾ç­–ï¼ˆ`../`ã®é©åˆ‡ãªå‡¦ç†ï¼‰

### 2. èªè¨¼ãƒ»èªå¯
- [ ] APIãƒˆãƒ¼ã‚¯ãƒ³ã¯ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã•ã‚Œã¦ã„ãªã„
- [ ] ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å®‰å…¨ã«èª­ã¿è¾¼ã‚“ã§ã„ã‚‹
- [ ] ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ãƒã‚§ãƒƒã‚¯ãŒé©åˆ‡

### 3. ãƒ‡ãƒ¼ã‚¿ä¿è­·
- [ ] æ©Ÿå¯†æƒ…å ±ã¯ãƒ­ã‚°ã«å‡ºåŠ›ã—ã¦ã„ãªã„
- [ ] ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã¯å¹³æ–‡ä¿å­˜ã•ã‚Œã¦ã„ãªã„
- [ ] HTTPSã‚’ä½¿ç”¨ï¼ˆHTTPç¦æ­¢ï¼‰

### 4. ä¾å­˜é–¢ä¿‚
- [ ] æ—¢çŸ¥ã®è„†å¼±æ€§ã‚’å«ã‚€crateã‚’ä½¿ç”¨ã—ã¦ã„ãªã„
- [ ] `cargo audit`ã§ãƒã‚§ãƒƒã‚¯æ¸ˆã¿

## Step 2: ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°

100ç‚¹æº€ç‚¹ã§ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ï¼ˆ90ç‚¹ä»¥ä¸Šå¿…é ˆï¼‰:

- **å…¥åŠ›ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³**: 25ç‚¹
- **èªè¨¼ãƒ»èªå¯**: 25ç‚¹
- **ãƒ‡ãƒ¼ã‚¿ä¿è­·**: 25ç‚¹
- **ä¾å­˜é–¢ä¿‚ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£**: 25ç‚¹

## Step 3: ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ

ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ:

```markdown
# ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ¬ãƒãƒ¼ãƒˆ

**Total Score**: 92/100

## è©³ç´°è©•ä¾¡

### å…¥åŠ›ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ (23/25)
âœ… ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã®ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè£…æ¸ˆã¿
âš ï¸ ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ï¼ˆç©ºæ–‡å­—åˆ—ï¼‰ã®ãƒ†ã‚¹ãƒˆä¸è¶³

### èªè¨¼ãƒ»èªå¯ (25/25)
âœ… APIãƒˆãƒ¼ã‚¯ãƒ³ã¯ç’°å¢ƒå¤‰æ•°ã‹ã‚‰èª­ã¿è¾¼ã¿
âœ… ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ãƒã‚§ãƒƒã‚¯å®Ÿè£…æ¸ˆã¿

### ãƒ‡ãƒ¼ã‚¿ä¿è­· (22/25)
âœ… æ©Ÿå¯†æƒ…å ±ã¯ãƒ­ã‚°å‡ºåŠ›ã—ã¦ã„ãªã„
âš ï¸ ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«å†…éƒ¨ãƒ‘ã‚¹æƒ…å ±ãŒå«ã¾ã‚Œã‚‹å¯èƒ½æ€§

### ä¾å­˜é–¢ä¿‚ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ (22/25)
âœ… `cargo audit`ã§è„†å¼±æ€§ãªã—
âš ï¸ ä¸€éƒ¨ã®crateãƒãƒ¼ã‚¸ãƒ§ãƒ³ãŒå¤ã„

## æ¨å¥¨äº‹é …

1. ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆã‚’è¿½åŠ 
2. ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰å†…éƒ¨æƒ…å ±ã‚’å‰Šé™¤
3. ä¾å­˜é–¢ä¿‚ã‚’æœ€æ–°ç‰ˆã«ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆ
```
```

## Configuration Options

Miyabi's behavior can be customized via `miyabi.toml` configuration file.

### Basic Configuration Structure

```toml
# miyabi.toml
[project]
name = "miyabi"
version = "2.0.0"
repository = "https://github.com/ShunsukeHayashi/Miyabi"

[github]
token_env = "GITHUB_TOKEN"
default_branch = "main"

[agents]
# Global Agent settings
max_concurrency = 5
default_reasoning_effort = "medium"

[agents.coordinator]
enabled = true
spec_path = ".claude/agents/specs/coding/coordinator-agent.md"
prompt_path = ".claude/agents/prompts/coding/coordinator-agent-prompt.md"

[agents.coordinator.llm]
model = "claude-sonnet-4-20250514"
max_tokens = 16000
reasoning_effort = "high"  # coordinator needs deep reasoning

[agents.codegen]
enabled = true
spec_path = ".claude/agents/specs/coding/codegen-agent-custom.md"  # Custom spec
prompt_path = ".claude/agents/prompts/coding/codegen-agent-prompt-custom.md"

[agents.codegen.llm]
model = "claude-sonnet-4-20250514"
max_tokens = 8000
reasoning_effort = "medium"

[agents.review]
enabled = true
spec_path = ".claude/agents/specs/coding/review-agent.md"
prompt_path = ".claude/agents/prompts/coding/review-agent-prompt-security.md"  # Custom prompt

[agents.review.llm]
model = "claude-sonnet-4-20250514"
max_tokens = 6000
reasoning_effort = "medium"

[agents.review.scoring]
# Custom scoring weights
quality_weight = 0.4
security_weight = 0.3  # Increased from default 0.2
maintainability_weight = 0.2
performance_weight = 0.1

[worktree]
base_path = ".worktrees"
auto_cleanup = true
max_worktrees = 10

[logging]
level = "info"  # trace, debug, info, warn, error
format = "json"  # json, pretty
output_dir = ".ai/logs"
```

### LLM Backend Selection

Miyabi supports multiple LLM backends:

```toml
[agents.codegen.llm]
# Option 1: Claude Sonnet 4 (default, most capable)
model = "claude-sonnet-4-20250514"
provider = "anthropic"

# Option 2: GPT-OSS-20B (open-source, self-hosted)
model = "gpt-oss-20b"
provider = "ollama"
endpoint = "http://localhost:11434"

# Option 3: Groq (fast inference)
model = "llama-3.1-70b"
provider = "groq"
api_key_env = "GROQ_API_KEY"

# Option 4: vLLM (self-hosted, optimized)
model = "meta-llama/Meta-Llama-3.1-70B"
provider = "vllm"
endpoint = "http://localhost:8000"
```

### Reasoning Effort Levels

Control the depth of reasoning for each Agent:

```toml
[agents.coordinator.llm]
reasoning_effort = "high"  # Deep analysis, slower, more accurate

[agents.codegen.llm]
reasoning_effort = "medium"  # Balanced

[agents.deployment.llm]
reasoning_effort = "low"  # Quick decisions, fast execution
```

**Effort Levels**:
- **Low**: Fast responses, basic reasoning (~1-2 seconds)
- **Medium**: Balanced reasoning and speed (~3-5 seconds)
- **High**: Deep analysis, complex decision-making (~5-10 seconds)

## Testing Custom Agents

Before deploying custom Agents to production, thorough testing is essential.

### Dry-Run Mode

Test your custom Agent without making actual changes:

```bash
miyabi agent run codegen --issue 270 --dry-run
```

**What Happens in Dry-Run**:
1. Agent reads the Issue and Task
2. Plans the execution (visible in logs)
3. Simulates file changes (no actual writes)
4. Reports what would have been done
5. No Git commits, no PR creation

**Expected Output**:

```
[DRY-RUN] CodeGenAgent Starting
[DRY-RUN] Read Issue #270: "Add custom error handling"
[DRY-RUN] Would generate files:
  - crates/miyabi-core/src/error.rs (145 lines)
  - crates/miyabi-core/tests/error_test.rs (78 lines)
[DRY-RUN] Would run: cargo test --package miyabi-core
[DRY-RUN] Would commit: "feat(core): add custom error handling with thiserror"
[DRY-RUN] Execution successful (no changes made)
```

### Log Analysis

Inspect Agent execution logs to verify behavior:

```bash
# View latest Agent execution logs
cat .ai/logs/agent-execution-$(date +%Y-%m-%d).json | jq .

# Filter CodeGenAgent logs
cat .ai/logs/agent-execution-$(date +%Y-%m-%d).json | jq 'select(.agent_type == "CodeGenAgent")'

# Check for errors
cat .ai/logs/agent-execution-$(date +%Y-%m-%d).json | jq 'select(.level == "error")'
```

**Example Log Entry**:

```json
{
  "timestamp": "2025-10-24T15:30:45Z",
  "level": "info",
  "agent_type": "CodeGenAgent",
  "issue_number": 270,
  "worktree_path": ".worktrees/issue-270",
  "message": "Generated error.rs with custom thiserror patterns",
  "files_created": [
    "crates/miyabi-core/src/error.rs"
  ],
  "metrics": {
    "lines_of_code": 145,
    "execution_time_ms": 3241
  }
}
```

### Validation Checklist

Before considering your custom Agent production-ready:

**Functional Validation**:
- [ ] Agent executes without errors in dry-run mode
- [ ] Generated code compiles (`cargo build`)
- [ ] Tests pass (`cargo test`)
- [ ] Custom rules are enforced (e.g., error handling patterns)
- [ ] Output files are in expected locations

**Quality Validation**:
- [ ] ReviewAgent scores 80+ points
- [ ] Code follows custom style guide
- [ ] Documentation is generated (Rustdoc)
- [ ] No Clippy warnings

**Integration Validation**:
- [ ] Agent works within Worktree workflow
- [ ] Conventional Commits are generated correctly
- [ ] EXECUTION_CONTEXT.md is updated properly
- [ ] Agent escalates correctly when needed

### Test Workflow

Here's a complete test workflow for a custom Agent:

```bash
# 1. Create a test Issue
gh issue create --title "Test custom CodeGenAgent" --body "Generate code with custom error handling"

# 2. Run Agent in dry-run mode
miyabi agent run codegen --issue 271 --dry-run

# 3. Review dry-run output
cat .ai/logs/agent-execution-$(date +%Y-%m-%d).json | jq 'select(.issue_number == 271)'

# 4. Run Agent for real (creates Worktree)
miyabi agent run codegen --issue 271

# 5. Inspect Worktree
cd .worktrees/issue-271
cat EXECUTION_CONTEXT.md
cat .agent-context.json

# 6. Verify generated code
cargo build --package miyabi-core
cargo test --package miyabi-core
cargo clippy --package miyabi-core

# 7. Check custom rules
rg "thiserror::Error" crates/miyabi-core/src/error.rs
rg 'error\("Failed to' crates/miyabi-core/src/error.rs

# 8. Return to main repo
cd ../..

# 9. Merge Worktree (if satisfied)
git merge worktree/issue-271

# 10. Cleanup
git worktree remove .worktrees/issue-271
```

## Real-World Examples

Let's explore some practical customization scenarios.

### Example 1: Custom Documentation Style

Your team requires specific documentation headers in all Rust files.

**Custom Spec Addition** (`.claude/agents/specs/coding/codegen-agent-custom.md`):

```markdown
## ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆè¦å‰‡

### ãƒ•ã‚¡ã‚¤ãƒ«ãƒ˜ãƒƒãƒ€ãƒ¼

ã™ã¹ã¦ã®Rustãƒ•ã‚¡ã‚¤ãƒ«ã«ä»¥ä¸‹ã®ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’è¿½åŠ :

```rust
// Copyright (c) 2025 Your Company
// Licensed under MIT License
//
// File: {filename}
// Purpose: {brief description}
// Author: CodeGenAgent (Autonomous)
// Created: {date}
```

### ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

ã™ã¹ã¦ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã«è©³ç´°ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ:

```rust
//! # Module Name
//!
//! Brief description of the module's purpose.
//!
//! ## Overview
//!
//! Detailed explanation of what this module does.
//!
//! ## Examples
//!
//! ```
//! use crate::module::Function;
//!
//! let result = Function::execute();
//! ```
```
```

### Example 2: Custom Test Patterns

Your team uses table-driven tests for comprehensive coverage.

**Custom Prompt Addition** (`.claude/agents/prompts/coding/codegen-agent-prompt-custom.md`):

```markdown
## Step 4: ãƒ†ãƒ¼ãƒ–ãƒ«é§†å‹•ãƒ†ã‚¹ãƒˆç”Ÿæˆ

ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆã¯ãƒ†ãƒ¼ãƒ–ãƒ«é§†å‹•ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ä½¿ç”¨:

```rust
#[cfg(test)]
mod tests {
    use super::*;

    #[tokio::test]
    async fn test_execute_multiple_scenarios() {
        let test_cases = vec![
            // (input, expected_output, description)
            ("valid_input", Ok(()), "æ­£å¸¸ãªã‚¤ãƒ³ãƒ—ãƒƒãƒˆ"),
            ("", Err(AgentError::InvalidInput), "ç©ºæ–‡å­—åˆ—"),
            ("toolong".repeat(100), Err(AgentError::InputTooLong), "é•·ã™ãã‚‹ã‚¤ãƒ³ãƒ—ãƒƒãƒˆ"),
        ];

        for (input, expected, description) in test_cases {
            let result = execute_task(input).await;
            assert_eq!(result, expected, "Failed: {}", description);
        }
    }
}
```
```

## Troubleshooting

### Issue: Custom Spec Not Being Used

**Symptom**: Agent ignores custom spec and uses default behavior.

**Solution**:
1. Check `miyabi.toml` configuration:
   ```bash
   cat miyabi.toml | grep spec_path
   ```
2. Verify file path is correct (relative to project root)
3. Restart Miyabi CLI if configuration was just changed

### Issue: Agent Fails with Custom Prompt

**Symptom**: Agent crashes or produces unexpected output with custom prompt.

**Solution**:
1. Validate prompt syntax (valid Markdown)
2. Check for missing context references (e.g., `EXECUTION_CONTEXT.md`)
3. Run in dry-run mode to see detailed error messages
4. Compare with original prompt to find syntax errors

### Issue: Configuration Not Loading

**Symptom**: `miyabi.toml` changes don't take effect.

**Solution**:
```bash
# Verify configuration is valid TOML
cargo install taplo-cli
taplo format --check miyabi.toml

# Check configuration is being loaded
miyabi config show
```

## Success Checklist

Before considering your Agent customization complete:

- [ ] Custom spec file created and referenced in `miyabi.toml`
- [ ] Custom prompt follows project standards
- [ ] Agent executes successfully in dry-run mode
- [ ] Agent produces expected output
- [ ] Custom rules are enforced (verified with tests)
- [ ] Documentation updated with customization details
- [ ] Team reviewed and approved customizations

## Next Steps

Congratulations! You've mastered Agent customization. Here's what to explore next:

1. **Tutorial 5: Worktree-Based Parallel Execution** - Learn how to run multiple custom Agents in parallel
2. **Tutorial 6: Label System Mastery** - Use Labels to trigger custom Agent workflows
3. **Tutorial 7: MCP Integration** - Extend Agents with external tools via MCP

## Resources

- **Agent Specs Repository**: `.claude/agents/specs/`
- **Agent Prompts Repository**: `.claude/agents/prompts/`
- **Configuration Guide**: `docs/CONFIGURATION.md`
- **Agent Development Guide**: `docs/AGENT_DEVELOPMENT_GUIDE.md`

---

**Tutorial Created**: 2025-10-24
**Last Updated**: 2025-10-24
**Author**: ContentCreationAgent (ã‹ãã¡ã‚ƒã‚“)

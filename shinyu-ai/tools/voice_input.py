#!/usr/bin/env python3
"""
éŸ³å£°å…¥åŠ›ã‚·ã‚¹ãƒ†ãƒ  - Whisper APIã‚’ä½¿ã£ãŸéŸ³å£°â†’ãƒ†ã‚­ã‚¹ãƒˆå¤‰æ›

ä½¿ã„æ–¹:
    python3 tools/voice_input.py

æ©Ÿèƒ½:
    1. ãƒã‚¤ã‚¯ã‹ã‚‰éŸ³å£°ã‚’éŒ²éŸ³ï¼ˆSpaceã‚­ãƒ¼ã§é–‹å§‹/åœæ­¢ï¼‰
    2. Whisper APIã§æ–‡å­—èµ·ã“ã—
    3. ãƒ†ã‚­ã‚¹ãƒˆã‚’æ¨™æº–å‡ºåŠ›ã«å‡ºåŠ›
"""

import os
import sys
import time
import tempfile
from pathlib import Path

try:
    import pyaudio
    import wave
    from pynput import keyboard
    from openai import OpenAI
except ImportError:
    print("âŒ å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
    print("æ¬¡ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ï¼š")
    print("pip3 install pyaudio pynput openai")
    sys.exit(1)


class VoiceRecorder:
    """éŸ³å£°éŒ²éŸ³ã‚¯ãƒ©ã‚¹"""

    def __init__(self):
        self.is_recording = False
        self.frames = []
        self.audio = pyaudio.PyAudio()
        self.stream = None

        # éŒ²éŸ³è¨­å®š
        self.CHUNK = 1024
        self.FORMAT = pyaudio.paInt16
        self.CHANNELS = 1
        self.RATE = 16000  # Whisper APIã®æ¨å¥¨ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆ

    def start_recording(self):
        """éŒ²éŸ³é–‹å§‹"""
        self.is_recording = True
        self.frames = []

        self.stream = self.audio.open(
            format=self.FORMAT,
            channels=self.CHANNELS,
            rate=self.RATE,
            input=True,
            frames_per_buffer=self.CHUNK,
            stream_callback=self._callback
        )

        print("ğŸ¤ éŒ²éŸ³ä¸­... (Spaceã‚­ãƒ¼ã§åœæ­¢)")
        self.stream.start_stream()

    def stop_recording(self):
        """éŒ²éŸ³åœæ­¢"""
        if self.stream:
            self.is_recording = False
            self.stream.stop_stream()
            self.stream.close()
            print("â¹ï¸  éŒ²éŸ³åœæ­¢")

    def _callback(self, in_data, frame_count, time_info, status):
        """éŒ²éŸ³ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
        if self.is_recording:
            self.frames.append(in_data)
        return (in_data, pyaudio.paContinue)

    def save_to_file(self, filename):
        """WAVãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        with wave.open(filename, 'wb') as wf:
            wf.setnchannels(self.CHANNELS)
            wf.setsampwidth(self.audio.get_sample_size(self.FORMAT))
            wf.setframerate(self.RATE)
            wf.writeframes(b''.join(self.frames))

    def cleanup(self):
        """ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        if self.stream:
            self.stream.close()
        self.audio.terminate()


def transcribe_audio(audio_file_path: str) -> str:
    """
    Whisper APIã§éŸ³å£°ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›

    Args:
        audio_file_path: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹

    Returns:
        æ–‡å­—èµ·ã“ã—ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ
    """
    # OpenAI APIã‚­ãƒ¼ã®ç¢ºèª
    api_key = os.environ.get("OPENAI_API_KEY")
    if not api_key:
        print("âŒ OPENAI_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        print("æ¬¡ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ï¼š")
        print("export OPENAI_API_KEY=your-api-key-here")
        sys.exit(1)

    client = OpenAI(api_key=api_key)

    print("ğŸ”„ Whisper APIã§æ–‡å­—èµ·ã“ã—ä¸­...")

    with open(audio_file_path, "rb") as audio_file:
        transcript = client.audio.transcriptions.create(
            model="whisper-1",
            file=audio_file,
            language="ja"  # æ—¥æœ¬èªæŒ‡å®š
        )

    return transcript.text


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("=" * 60)
    print("ğŸ¤ éŸ³å£°å…¥åŠ›ã‚·ã‚¹ãƒ†ãƒ  - Whisper APIç‰ˆ")
    print("=" * 60)
    print()
    print("æ“ä½œæ–¹æ³•:")
    print("  Spaceã‚­ãƒ¼: éŒ²éŸ³é–‹å§‹/åœæ­¢")
    print("  Ctrl+C: çµ‚äº†")
    print()

    recorder = VoiceRecorder()
    is_recording = False

    def on_press(key):
        """ã‚­ãƒ¼æŠ¼ä¸‹æ™‚ã®å‡¦ç†"""
        nonlocal is_recording

        try:
            if key == keyboard.Key.space:
                if not is_recording:
                    recorder.start_recording()
                    is_recording = True
                else:
                    recorder.stop_recording()
                    is_recording = False

                    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
                    with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp_file:
                        tmp_filename = tmp_file.name

                    recorder.save_to_file(tmp_filename)
                    print(f"ğŸ’¾ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜: {tmp_filename}")

                    # Whisper APIã§æ–‡å­—èµ·ã“ã—
                    try:
                        text = transcribe_audio(tmp_filename)
                        print()
                        print("=" * 60)
                        print("ğŸ“ æ–‡å­—èµ·ã“ã—çµæœ:")
                        print("=" * 60)
                        print(text)
                        print("=" * 60)
                        print()

                        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
                        os.unlink(tmp_filename)

                    except Exception as e:
                        print(f"âŒ æ–‡å­—èµ·ã“ã—ã‚¨ãƒ©ãƒ¼: {e}")

                    print("Spaceã‚­ãƒ¼ã§å†åº¦éŒ²éŸ³ã§ãã¾ã™")

        except AttributeError:
            pass

    # ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ãƒªã‚¹ãƒŠãƒ¼èµ·å‹•
    listener = keyboard.Listener(on_press=on_press)
    listener.start()

    try:
        # ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—
        while True:
            time.sleep(0.1)
    except KeyboardInterrupt:
        print("\nğŸ‘‹ çµ‚äº†ã—ã¾ã™")
        recorder.cleanup()
        listener.stop()


if __name__ == "__main__":
    main()

# Mac mini LLM Server Setup Guide

åˆ¥ç«¯æœ«ã®Mac miniã‚’GPT-OSS-20Bå°‚ç”¨LLMã‚µãƒ¼ãƒãƒ¼ã¨ã—ã¦æ§‹ç¯‰ã™ã‚‹ã‚¬ã‚¤ãƒ‰

---

## ğŸ¯ æ§‹æˆæ¦‚è¦

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  é–‹ç™ºãƒã‚·ãƒ³ (a003)       â”‚         â”‚  Mac mini LLM Server    â”‚
â”‚  192.168.3.x            â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”¤  192.168.3.27 / .26     â”‚
â”‚                         â”‚  HTTP   â”‚                         â”‚
â”‚  - miyabi-cli           â”‚         â”‚  - Ollama               â”‚
â”‚  - miyabi-llm client    â”‚         â”‚  - gpt-oss:20b          â”‚
â”‚  - VS Code + Claude     â”‚         â”‚  - API Server :11434    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ãƒ¡ãƒªãƒƒãƒˆ**:
- âœ… é–‹ç™ºãƒã‚·ãƒ³ã®ãƒªã‚½ãƒ¼ã‚¹ç¯€ç´„
- âœ… 24/7 ç¨¼åƒå¯èƒ½
- âœ… ãƒ­ãƒ¼ã‚«ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ (ä½ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·)
- âœ… ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ä¿è­· (å¤–éƒ¨APIä¸è¦)
- âœ… è¤‡æ•°ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‹ã‚‰åˆ©ç”¨å¯èƒ½

---

## ğŸ“‹ å‰ææ¡ä»¶

### Mac mini ã‚µãƒ¼ãƒãƒ¼å´

| é …ç›® | æœ€å°è¦ä»¶ | æ¨å¥¨ |
|------|----------|------|
| ãƒ¢ãƒ‡ãƒ« | Mac mini M1 (2020) | Mac mini M2 Pro (2023) |
| RAM | 16GB | 32GB |
| Storage | 50GB ç©ºã | 100GB ç©ºã |
| macOS | macOS 12 Monterey | macOS 14 Sonoma |
| ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ | ã‚®ã‚¬ãƒ“ãƒƒãƒˆ Ethernet | ã‚®ã‚¬ãƒ“ãƒƒãƒˆ Ethernet |

### é–‹ç™ºãƒã‚·ãƒ³å´

- SSH ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½
- åŒä¸€ LAN (192.168.3.x)
- Rust + Cargo ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿

---

## ğŸš€ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æ‰‹é †

### Phase 1: Mac mini ã‚µãƒ¼ãƒãƒ¼æº–å‚™ (15åˆ†)

#### Step 1-1: SSH ã‚¢ã‚¯ã‚»ã‚¹ç¢ºèª

**é–‹ç™ºãƒã‚·ãƒ³ã‹ã‚‰**:
```bash
# Mac mini ã« SSH æ¥ç¶š
ssh macmini    # ã¾ãŸã¯ ssh macmini2
# ã¾ãŸã¯
ssh a003@192.168.3.27
ssh shunsukehayashi@192.168.3.26
```

**æ¥ç¶šã§ããªã„å ´åˆ** (Mac mini å´ã§è¨­å®š):
```bash
# ã‚·ã‚¹ãƒ†ãƒ è¨­å®š â†’ ä¸€èˆ¬ â†’ å…±æœ‰ â†’ ãƒªãƒ¢ãƒ¼ãƒˆãƒ­ã‚°ã‚¤ãƒ³ â†’ ON

# ã¾ãŸã¯ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³
sudo systemsetup -setremotelogin on

# ç¢ºèª
sudo systemsetup -getremotelogin
```

#### Step 1-2: Homebrew ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ« (Mac mini å´)

```bash
# SSH ã§ Mac mini ã«æ¥ç¶šã—ãŸçŠ¶æ…‹ã§

# Homebrew ç¢ºèª
brew --version

# ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ãªã„å ´åˆ
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"

# PATH è¨­å®š (Apple Silicon ã®å ´åˆ)
echo 'eval "$(/opt/homebrew/bin/brew shellenv)"' >> ~/.zprofile
eval "$(/opt/homebrew/bin/brew shellenv)"
```

#### Step 1-3: Ollama ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ« (Mac mini å´)

```bash
# Ollama ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
brew install ollama

# ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç¢ºèª
ollama --version
# ä¾‹: ollama version is 0.5.2
```

#### Step 1-4: GPT-OSS-20B ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (Mac mini å´)

```bash
# ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (ç´„16GBã€10-20åˆ†)
ollama pull gpt-oss:20b
```

**ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰é€²æ—**:
```
pulling manifest
pulling 4a03f05b1f4a... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– 9.5 GB
pulling fe94d09f12cf... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– 6.2 GB
pulling 8ab4849b038c... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  254 B
pulling 566c7c09a699... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   94 B
pulling 4ed56a0719af... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  483 B
verifying sha256 digest
writing manifest
success
```

**ç¢ºèª**:
```bash
# ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ä¸€è¦§
ollama list

# å‡ºåŠ›ä¾‹
NAME             ID              SIZE    MODIFIED
gpt-oss:20b      a1b2c3d4e5f6    16 GB   2 minutes ago
```

#### Step 1-5: Ollama API ã‚µãƒ¼ãƒãƒ¼èµ·å‹• (Mac mini å´)

**æ–¹æ³•1: ãƒ•ã‚©ã‚¢ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å®Ÿè¡Œ** (ãƒ†ã‚¹ãƒˆç”¨)
```bash
# API ã‚µãƒ¼ãƒãƒ¼èµ·å‹•
ollama serve

# å‡ºåŠ›
time=2025-10-17T00:30:00.000+09:00 level=INFO source=routes.go:1153 msg="Listening on 127.0.0.1:11434 (version 0.5.2)"
time=2025-10-17T00:30:00.001+09:00 level=INFO source=common.go:135 msg="Extracting embedded files" dir=/tmp/ollama-1234567
```

**æ–¹æ³•2: ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å®Ÿè¡Œ** (æ¨å¥¨)
```bash
# ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰èµ·å‹•
nohup ollama serve > ~/ollama.log 2>&1 &

# ãƒ—ãƒ­ã‚»ã‚¹ç¢ºèª
ps aux | grep ollama
# ã¾ãŸã¯
pgrep -f ollama

# ãƒ­ã‚°ç¢ºèª
tail -f ~/ollama.log
```

**æ–¹æ³•3: LaunchAgent (è‡ªå‹•èµ·å‹•)** (æœ€æ¨å¥¨)
```bash
# LaunchAgent plist ä½œæˆ
cat > ~/Library/LaunchAgents/com.ollama.server.plist <<'EOF'
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
    <key>Label</key>
    <string>com.ollama.server</string>
    <key>ProgramArguments</key>
    <array>
        <string>/opt/homebrew/bin/ollama</string>
        <string>serve</string>
    </array>
    <key>RunAtLoad</key>
    <true/>
    <key>KeepAlive</key>
    <true/>
    <key>StandardOutPath</key>
    <string>/tmp/ollama.stdout.log</string>
    <key>StandardErrorPath</key>
    <string>/tmp/ollama.stderr.log</string>
</dict>
</plist>
EOF

# LaunchAgent èª­ã¿è¾¼ã¿
launchctl load ~/Library/LaunchAgents/com.ollama.server.plist

# ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç¢ºèª
launchctl list | grep ollama

# åœæ­¢
launchctl unload ~/Library/LaunchAgents/com.ollama.server.plist
```

#### Step 1-6: ãƒ•ã‚¡ã‚¤ã‚¢ã‚¦ã‚©ãƒ¼ãƒ«è¨­å®š (Mac mini å´)

Ollama ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ `127.0.0.1:11434` (localhost ã®ã¿) ã§èµ·å‹•ã—ã¾ã™ã€‚
LAN ã‹ã‚‰ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ã«ã¯ç’°å¢ƒå¤‰æ•°ã‚’è¨­å®šã—ã¾ã™ã€‚

```bash
# ~/.zshrc ã¾ãŸã¯ ~/.bash_profile ã«è¿½åŠ 
echo 'export OLLAMA_HOST=0.0.0.0:11434' >> ~/.zshrc
source ~/.zshrc

# Ollama å†èµ·å‹•
launchctl unload ~/Library/LaunchAgents/com.ollama.server.plist
launchctl load ~/Library/LaunchAgents/com.ollama.server.plist

# ã¾ãŸã¯æ‰‹å‹•å†èµ·å‹•
pkill ollama
OLLAMA_HOST=0.0.0.0:11434 ollama serve &
```

**macOS ãƒ•ã‚¡ã‚¤ã‚¢ã‚¦ã‚©ãƒ¼ãƒ«è¨±å¯**:
```bash
# ã‚·ã‚¹ãƒ†ãƒ è¨­å®š â†’ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ â†’ ãƒ•ã‚¡ã‚¤ã‚¢ã‚¦ã‚©ãƒ¼ãƒ«
# "ollama" ã‚’è¨±å¯

# ã¾ãŸã¯ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³
sudo /usr/libexec/ApplicationFirewall/socketfilterfw --add /opt/homebrew/bin/ollama
sudo /usr/libexec/ApplicationFirewall/socketfilterfw --unblockapp /opt/homebrew/bin/ollama
```

---

### Phase 2: æ¥ç¶šãƒ†ã‚¹ãƒˆ (5åˆ†)

#### Step 2-1: ãƒ­ãƒ¼ã‚«ãƒ«ãƒ†ã‚¹ãƒˆ (Mac mini å´)

```bash
# Mac mini ä¸Šã§ãƒ†ã‚¹ãƒˆ
curl http://localhost:11434/api/generate -d '{
  "model": "gpt-oss:20b",
  "prompt": "Write a hello world in Rust",
  "stream": false
}'
```

**æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›**:
```json
{
  "model": "gpt-oss:20b",
  "created_at": "2025-10-17T00:35:00.123456Z",
  "response": "fn main() {\n    println!(\"Hello, world!\");\n}",
  "done": true,
  "context": [128, 256, ...],
  "total_duration": 5234567890,
  "load_duration": 1234567,
  "prompt_eval_count": 10,
  "prompt_eval_duration": 2345678901,
  "eval_count": 20,
  "eval_duration": 2888888989
}
```

#### Step 2-2: LAN æ¥ç¶šãƒ†ã‚¹ãƒˆ (é–‹ç™ºãƒã‚·ãƒ³å´)

```bash
# é–‹ç™ºãƒã‚·ãƒ³ã‹ã‚‰ Mac mini ã«ã‚¢ã‚¯ã‚»ã‚¹
curl http://192.168.3.27:11434/api/generate -d '{
  "model": "gpt-oss:20b",
  "prompt": "Write a hello world in Rust",
  "stream": false
}'

# ã¾ãŸã¯ macmini2 ã®å ´åˆ
curl http://192.168.3.26:11434/api/generate -d '{
  "model": "gpt-oss:20b",
  "prompt": "Write a hello world in Rust",
  "stream": false
}'
```

**ã‚¨ãƒ©ãƒ¼ãŒå‡ºã‚‹å ´åˆ**:
```bash
# Mac mini å´ã§ OLLAMA_HOST ã‚’ç¢ºèª
echo $OLLAMA_HOST
# å‡ºåŠ›: 0.0.0.0:11434 (å¿…é ˆ)

# netstat ã§ç¢ºèª
netstat -an | grep 11434
# å‡ºåŠ›: tcp4  0  0  *.11434  *.*  LISTEN

# å†èµ·å‹•
pkill ollama
OLLAMA_HOST=0.0.0.0:11434 nohup ollama serve > ~/ollama.log 2>&1 &
```

---

### Phase 3: Miyabi çµ±åˆ (10åˆ†)

#### Step 3-1: miyabi-llm è¨­å®šæ›´æ–°

**`crates/miyabi-llm/src/provider.rs` ã« Mac mini ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆè¿½åŠ **:

```rust
impl GPTOSSProvider {
    // æ—¢å­˜ãƒ¡ã‚½ãƒƒãƒ‰ã¯ãã®ã¾ã¾

    /// Create a Mac mini Ollama provider
    ///
    /// # Arguments
    /// * `mac_mini_ip` - Mac mini ã® IP ã‚¢ãƒ‰ãƒ¬ã‚¹ (ä¾‹: "192.168.3.27")
    ///
    /// # Example
    /// ```rust,no_run
    /// use miyabi_llm::GPTOSSProvider;
    ///
    /// let provider = GPTOSSProvider::new_mac_mini("192.168.3.27").unwrap();
    /// ```
    pub fn new_mac_mini(mac_mini_ip: impl Into<String>) -> Result<Self> {
        let ip = mac_mini_ip.into();
        let endpoint = format!("http://{}:11434", ip);
        let mut provider = Self::new(endpoint, None)?;
        provider.model = "gpt-oss:20b".to_string();
        Ok(provider)
    }

    /// Create a Mac mini Ollama provider with custom port
    pub fn new_mac_mini_custom(
        mac_mini_ip: impl Into<String>,
        port: u16,
    ) -> Result<Self> {
        let ip = mac_mini_ip.into();
        let endpoint = format!("http://{}:{}", ip, port);
        let mut provider = Self::new(endpoint, None)?;
        provider.model = "gpt-oss:20b".to_string();
        Ok(provider)
    }
}
```

#### Step 3-2: ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰è¿½åŠ 

**`crates/miyabi-llm/src/provider.rs` ã® `#[cfg(test)]` ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«è¿½åŠ **:

```rust
#[test]
fn test_provider_creation_mac_mini() {
    let provider = GPTOSSProvider::new_mac_mini("192.168.3.27").unwrap();
    assert_eq!(provider.model, "gpt-oss:20b");
    assert_eq!(provider.endpoint, "http://192.168.3.27:11434");
    assert_eq!(provider.api_key, None);
}

#[test]
fn test_provider_creation_mac_mini_custom_port() {
    let provider = GPTOSSProvider::new_mac_mini_custom("192.168.3.27", 8080).unwrap();
    assert_eq!(provider.model, "gpt-oss:20b");
    assert_eq!(provider.endpoint, "http://192.168.3.27:8080");
}
```

#### Step 3-3: çµ±åˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œ

```bash
# ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
cargo test --package miyabi-llm test_provider_creation_mac_mini

# å®Ÿéš›ã®æ¥ç¶šãƒ†ã‚¹ãƒˆ (Mac mini ã‚µãƒ¼ãƒãƒ¼èµ·å‹•æ¸ˆã¿å‰æ)
cat > /tmp/test_mac_mini.rs <<'EOF'
use miyabi_llm::{LLMProvider, GPTOSSProvider, LLMRequest};

#[tokio::main]
async fn main() -> anyhow::Result<()> {
    // Mac mini provider
    let provider = GPTOSSProvider::new_mac_mini("192.168.3.27")?;

    // ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
    let request = LLMRequest::new("Write a Rust function to calculate factorial");

    // ç”Ÿæˆ
    println!("Connecting to Mac mini LLM server...");
    let response = provider.generate(&request).await?;

    println!("Response: {}", response.text);
    println!("Tokens used: {}", response.tokens_used);

    Ok(())
}
EOF

# å®Ÿè¡Œ (miyabi-private ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã§)
cargo run --example test_mac_mini
```

#### Step 3-4: `.miyabi.yml` è¨­å®š

```yaml
# .miyabi.yml
llm:
  provider: "mac_mini"  # "groq" | "vllm" | "ollama" | "mac_mini"

  # Mac mini Ollama server
  mac_mini:
    endpoint: "http://192.168.3.27:11434"  # ã¾ãŸã¯ 192.168.3.26
    model: "gpt-oss:20b"

  # Fallback to Groq
  groq:
    api_key: "${GROQ_API_KEY}"
    model: "openai/gpt-oss-20b"

  default_temperature: 0.2
  default_max_tokens: 4096
  default_reasoning_effort: "medium"
```

#### Step 3-5: ç’°å¢ƒå¤‰æ•°è¨­å®š (é–‹ç™ºãƒã‚·ãƒ³)

```bash
# ~/.zshrc ã«è¿½åŠ 
export MAC_MINI_LLM_ENDPOINT="http://192.168.3.27:11434"

# ã¾ãŸã¯ macmini2 ã®å ´åˆ
export MAC_MINI_LLM_ENDPOINT="http://192.168.3.26:11434"

# åæ˜ 
source ~/.zshrc
```

---

### Phase 4: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ (10åˆ†)

#### Step 4-1: ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚¹ã‚¯ãƒªãƒ—ãƒˆä½œæˆ

```bash
# ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ
cat > /tmp/benchmark_mac_mini.sh <<'EOF'
#!/bin/bash

MAC_MINI_ENDPOINT="http://192.168.3.27:11434"

echo "=== Mac mini LLM Server Benchmark ==="
echo "Endpoint: $MAC_MINI_ENDPOINT"
echo ""

# Test 1: Simple prompt
echo "Test 1: Simple prompt"
time curl -s $MAC_MINI_ENDPOINT/api/generate -d '{
  "model": "gpt-oss:20b",
  "prompt": "Write hello world in Rust",
  "stream": false
}' | jq -r '.response'

echo ""

# Test 2: Complex prompt
echo "Test 2: Complex prompt"
time curl -s $MAC_MINI_ENDPOINT/api/generate -d '{
  "model": "gpt-oss:20b",
  "prompt": "Explain Rust ownership and borrowing with examples",
  "stream": false
}' | jq -r '.response'

echo ""

# Test 3: 10 sequential requests
echo "Test 3: 10 sequential requests"
for i in {1..10}; do
  echo "Request $i/10..."
  curl -s $MAC_MINI_ENDPOINT/api/generate -d "{
    \"model\": \"gpt-oss:20b\",
    \"prompt\": \"Count to $i\",
    \"stream\": false
  }" > /dev/null
done

echo "Done!"
EOF

chmod +x /tmp/benchmark_mac_mini.sh
/tmp/benchmark_mac_mini.sh
```

#### Step 4-2: æœŸå¾…ã•ã‚Œã‚‹ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹

| Mac mini ãƒ¢ãƒ‡ãƒ« | æ¨è«–é€Ÿåº¦ | ãƒ¬ã‚¤ãƒ†ãƒ³ã‚· | ãƒ¡ãƒ¢ãƒªä½¿ç”¨ |
|----------------|---------|-----------|-----------|
| M1 (16GB) | 30-50 t/s | 10-20ç§’ | 14-16GB |
| M2 (16GB) | 50-70 t/s | 7-15ç§’ | 14-16GB |
| M2 Pro (32GB) | 70-100 t/s | 5-10ç§’ | 14-16GB |
| M3 Pro (32GB) | 80-120 t/s | 4-8ç§’ | 14-16GB |

#### Step 4-3: ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°

**Mac mini å´ã§ãƒªã‚½ãƒ¼ã‚¹ç›£è¦–**:
```bash
# CPU/ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡
top -pid $(pgrep ollama)

# ã¾ãŸã¯ã‚ˆã‚Šè©³ç´°
htop  # brew install htop

# ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®ã¿
ps aux | grep ollama | awk '{print $4}'  # ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡(%)
```

---

### Phase 5: ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

#### å•é¡Œ1: "Connection refused"

**ç—‡çŠ¶**: é–‹ç™ºãƒã‚·ãƒ³ã‹ã‚‰æ¥ç¶šã§ããªã„

**åŸå› ã¨è§£æ±ºç­–**:
```bash
# Mac mini å´ã§ç¢ºèª

# 1. Ollama ãŒèµ·å‹•ã—ã¦ã„ã‚‹ã‹
pgrep ollama || echo "Ollama not running"

# 2. æ­£ã—ã„ãƒ›ã‚¹ãƒˆã§ãƒªãƒƒã‚¹ãƒ³ã—ã¦ã„ã‚‹ã‹
netstat -an | grep 11434
# å¿…è¦ãªå‡ºåŠ›: tcp4  0  0  *.11434  *.*  LISTEN
# NG ãªå‡ºåŠ›: tcp4  0  0  127.0.0.1.11434  *.*  LISTEN

# 3. OLLAMA_HOST è¨­å®šç¢ºèª
echo $OLLAMA_HOST
# å¿…è¦: 0.0.0.0:11434

# 4. å†èµ·å‹•
export OLLAMA_HOST=0.0.0.0:11434
pkill ollama
ollama serve &
```

#### å•é¡Œ2: "Model not found"

**ç—‡çŠ¶**: `{"error":"model 'gpt-oss:20b' not found"}`

**è§£æ±ºç­–**:
```bash
# Mac mini å´ã§

# ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ç¢ºèª
ollama list

# gpt-oss:20b ãŒãªã„å ´åˆã€å†ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
ollama pull gpt-oss:20b

# ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰é€²è¡Œä¸­ã®å ´åˆã¯å¾…ã¤
watch -n 5 ollama list
```

#### å•é¡Œ3: æ¨è«–ãŒé…ã„

**ç—‡çŠ¶**: ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã« 30ç§’ä»¥ä¸Šã‹ã‹ã‚‹

**åŸå› ã¨è§£æ±ºç­–**:
```bash
# Mac mini å´ã§

# 1. ãƒ¡ãƒ¢ãƒªã‚¹ãƒ¯ãƒƒãƒ—ç¢ºèª
vm_stat | grep "Pages swapped"
# ã‚¹ãƒ¯ãƒƒãƒ—ãŒå¤šã„å ´åˆã¯ RAM ä¸è¶³

# 2. CPU ä½¿ç”¨ç‡ç¢ºèª
top -l 1 | grep "CPU usage"

# 3. è»½é‡ãƒ¢ãƒ‡ãƒ«ã«åˆ‡ã‚Šæ›¿ãˆ
ollama pull gpt-oss:20b-q4_0  # 4-bité‡å­åŒ–ç‰ˆ
# .miyabi.yml ã§ model ã‚’ "gpt-oss:20b-q4_0" ã«å¤‰æ›´
```

#### å•é¡Œ4: Mac mini ãŒã‚¹ãƒªãƒ¼ãƒ—ã™ã‚‹

**è§£æ±ºç­–**:
```bash
# Mac mini å´ã§

# ã‚¹ãƒªãƒ¼ãƒ—ç„¡åŠ¹åŒ– (é›»æºæ¥ç¶šæ™‚)
sudo pmset -c sleep 0
sudo pmset -c disksleep 0
sudo pmset -c displaysleep 10

# ç¢ºèª
pmset -g

# å…ƒã«æˆ»ã™
sudo pmset -c sleep 10
```

---

## ğŸ“Š ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹æˆè©³ç´°

### SSH ãƒˆãƒ³ãƒãƒ«çµŒç”± (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)

å¤–å‡ºå…ˆã‹ã‚‰ä½¿ç”¨ã™ã‚‹å ´åˆ:

```bash
# é–‹ç™ºãƒã‚·ãƒ³ã§ SSH ãƒˆãƒ³ãƒãƒ«ä½œæˆ
ssh -L 11434:localhost:11434 macmini

# åˆ¥ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§ localhost çµŒç”±ã§ã‚¢ã‚¯ã‚»ã‚¹
curl http://localhost:11434/api/generate -d '...'
```

### è¤‡æ•°ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå¯¾å¿œ

```bash
# Mac mini å´ã§æ¥ç¶šæ•°åˆ¶é™ãªã— (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ)
# Ollama ã¯è¤‡æ•°ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«å¯¾å¿œ

# åŒæ™‚å®Ÿè¡Œãƒ†ã‚¹ãƒˆ (é–‹ç™ºãƒã‚·ãƒ³å´)
for i in {1..5}; do
  curl http://192.168.3.27:11434/api/generate -d "{
    \"model\": \"gpt-oss:20b\",
    \"prompt\": \"Test $i\"
  }" &
done
wait
```

---

## ğŸ”§ é«˜åº¦ãªè¨­å®š

### 1. Nginx ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚· (Mac mini å´)

```bash
# Nginx ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
brew install nginx

# è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
sudo tee /opt/homebrew/etc/nginx/servers/ollama.conf <<'EOF'
upstream ollama_backend {
    server 127.0.0.1:11434;
}

server {
    listen 8080;
    server_name localhost;

    location /api/ {
        proxy_pass http://ollama_backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_connect_timeout 300s;
        proxy_send_timeout 300s;
        proxy_read_timeout 300s;
    }
}
EOF

# Nginx èµ·å‹•
sudo nginx
# ã¾ãŸã¯
brew services start nginx

# ãƒ†ã‚¹ãƒˆ
curl http://192.168.3.27:8080/api/generate -d '...'
```

### 2. ãƒ­ã‚°ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ (Mac mini å´)

```bash
# logrotate è¨­å®š
brew install logrotate

sudo tee /opt/homebrew/etc/logrotate.d/ollama <<'EOF'
/tmp/ollama.*.log {
    daily
    rotate 7
    compress
    delaycompress
    missingok
    notifempty
    create 0644 $(whoami) staff
}
EOF

# æ‰‹å‹•å®Ÿè¡Œ
logrotate /opt/homebrew/etc/logrotate.d/ollama
```

### 3. Prometheus ãƒ¡ãƒˆãƒªã‚¯ã‚¹ (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)

```bash
# Ollama ã«ã¯ãƒ“ãƒ«ãƒˆã‚¤ãƒ³ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãŒãªã„ãŸã‚ã€ã‚«ã‚¹ã‚¿ãƒ å®Ÿè£…ãŒå¿…è¦
# å°†æ¥ã®æ‹¡å¼µã¨ã—ã¦æ¤œè¨
```

---

## ğŸ“‹ ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

### ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†ç¢ºèª

- [ ] Mac mini ã« SSH æ¥ç¶šã§ãã‚‹
- [ ] Ollama ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å®Œäº†
- [ ] gpt-oss:20b ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº† (16GB)
- [ ] `OLLAMA_HOST=0.0.0.0:11434` è¨­å®šæ¸ˆã¿
- [ ] LaunchAgent ã§è‡ªå‹•èµ·å‹•è¨­å®š
- [ ] ãƒ•ã‚¡ã‚¤ã‚¢ã‚¦ã‚©ãƒ¼ãƒ«è¨±å¯è¨­å®š
- [ ] ãƒ­ãƒ¼ã‚«ãƒ«ãƒ†ã‚¹ãƒˆæˆåŠŸ (Mac mini ä¸Š)
- [ ] LAN ãƒ†ã‚¹ãƒˆæˆåŠŸ (é–‹ç™ºãƒã‚·ãƒ³ã‹ã‚‰)
- [ ] miyabi-llm çµ±åˆãƒ†ã‚¹ãƒˆæˆåŠŸ
- [ ] ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆå®Œäº†

### é‹ç”¨ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

- [ ] LaunchAgent ã§è‡ªå‹•èµ·å‹•ç¢ºèª
- [ ] ãƒ­ã‚°ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®š
- [ ] ãƒ‡ã‚£ã‚¹ã‚¯ã‚¹ãƒšãƒ¼ã‚¹ç›£è¦– (50GBä»¥ä¸Šæ¨å¥¨)
- [ ] ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ç›£è¦– (16GB ä¸­ 14-15GB)
- [ ] ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šç¢ºèª (ping 192.168.3.27)

---

## ğŸ“š å‚è€ƒæƒ…å ±

### SSH è¨­å®š (é–‹ç™ºãƒã‚·ãƒ³ ~/.ssh/config)

```
Host macmini
    HostName 192.168.3.27
    User a003
    IdentityFile ~/.ssh/id_ed25519_macmini

Host macmini2
    HostName 192.168.3.26
    User shunsukehayashi
    IdentityFile ~/.ssh/id_ed25519_macmini2
```

### Ollama API ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

- Generate: POST `/api/generate`
- Chat: POST `/api/chat`
- List Models: GET `/api/tags`
- Show Model: POST `/api/show`

---

## ğŸ¯ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

1. **Phase 2 é–‹å§‹** - CodeGenAgent ã«çµ±åˆ
2. **ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯** - Claude Code ã¨æ¯”è¼ƒ
3. **æœ€é©åŒ–** - ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°

---

**æœ€çµ‚æ›´æ–°**: 2025-10-17
**å¯¾è±¡ç’°å¢ƒ**: Mac mini M1/M2/M3 (16GB+)
**ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹**: âœ… å®Œå…¨å‹•ä½œç¢ºèªæ¸ˆã¿

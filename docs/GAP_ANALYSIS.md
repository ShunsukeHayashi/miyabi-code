# Miyabi Gap Analysis - Requirements vs Implementation

**Document Version**: 1.0.0
**Last Updated**: 2025-10-25
**Status**: Phase 0 - Complete

---

## ğŸ“‹ Executive Summary

æœ¬ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯ã€[SYSTEM_REQUIREMENTS_V2.md](SYSTEM_REQUIREMENTS_V2.md)ã§å®šç¾©ã—ãŸè¦ä»¶ã¨ã€[EXISTING_SYSTEM_ANALYSIS.md](EXISTING_SYSTEM_ANALYSIS.md)ã§åˆ†æã—ãŸæ—¢å­˜å®Ÿè£…ã®å·®åˆ†ã‚’æ˜ç¢ºåŒ–ã—ã¾ã™ã€‚

**åˆ†æçµæœ**:
- âœ… **å®Ÿè£…æ¸ˆã¿æ©Ÿèƒ½**: 65% (åŸºæœ¬Agentã€Worktreeã€LLMã€GitHubçµ±åˆ)
- ğŸŸ¡ **æ‹¡å¼µå¿…è¦æ©Ÿèƒ½**: 20% (5-Worldså¯¾å¿œã€è©•ä¾¡ã‚¹ã‚³ã‚¢)
- âŒ **æœªå®Ÿè£…æ©Ÿèƒ½**: 15% (Persistence, Security, Observability, Cost)

---

## ğŸ¯ Core Requirements Gap

### CR-1: 5-Worlds Quality Assurance Strategy

**è¦ä»¶**: å…¨ã‚³ãƒ¼ãƒ‰ç”Ÿæˆã‚¿ã‚¹ã‚¯ã§5ã¤ã®ãƒ‘ãƒ©ãƒ¬ãƒ«ãƒ¯ãƒ¼ãƒ«ãƒ‰ã‚’ä¸¦åˆ—å®Ÿè¡Œã—ã€è©•ä¾¡å¾Œã«æœ€è‰¯ã®1ã¤ã‚’é¸æŠ

**ç¾çŠ¶**:
```diff
- å˜ä¸€å®Ÿè¡Œã®ã¿
- WorldIdæ¦‚å¿µãªã—
- è©•ä¾¡ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ãªã—
```

**Gap**:
```diff
+ å¿…è¦ãªå®Ÿè£…:
+ 1. WorldIdå‹å®šç¾© (Alpha, Beta, Gamma, Delta, Epsilon)
+ 2. WorldConfig (model, temperature, prompt_variant)
+ 3. FiveWorldsManager (spawn_all_worlds, cleanup_all_worlds)
+ 4. EvaluationScore (100ç‚¹æº€ç‚¹ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°)
+ 5. å‹è€…é¸æŠãƒ­ã‚¸ãƒƒã‚¯
```

**å®Ÿè£…å„ªå…ˆåº¦**: ğŸ”´ **Critical** (P0)
**å®Ÿè£…å·¥æ•°**: 7-10æ—¥

---

### CR-2: Git Worktree Isolation

**è¦ä»¶**: å„WorldãŒå®Œå…¨ã«ç‹¬ç«‹ã—ãŸGit Worktreeã§å®Ÿè¡Œ

**ç¾çŠ¶**:
```diff
+ åŸºæœ¬çš„ãªWorktreeä½œæˆ/å‰Šé™¤ã¯å®Ÿè£…æ¸ˆã¿
- 5-Worldså°‚ç”¨ç®¡ç†ãªã—
- WorldIdå¯¾å¿œãªã—
```

**Gap**:
```diff
+ å¿…è¦ãªå®Ÿè£…:
+ 1. FiveWorldsManager (5ã¤ã®Worktreeã‚’ç®¡ç†)
+ 2. WorldIdåˆ¥ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ 
+    - worktrees/world-Alpha/issue-270/
+    - worktrees/world-Beta/issue-270/
+    - ...
+ 3. ä¸¦åˆ—å®Ÿè¡Œæ™‚ã®å¹²æ¸‰é˜²æ­¢
```

**å®Ÿè£…å„ªå…ˆåº¦**: ğŸ”´ **Critical** (P0)
**å®Ÿè£…å·¥æ•°**: 3-5æ—¥

---

## ğŸ›¡ï¸ Phase-by-Phase Gap Analysis

### Phase 1: Error Handling Strategy

| è¦ä»¶ID | è¦ä»¶ | ç¾çŠ¶ | Gap | å„ªå…ˆåº¦ | å·¥æ•° |
|--------|------|------|-----|--------|------|
| REQ-ERR-1 | Retry Policy (3å›, æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•) | âŒ ãªã— | retry_with_backoff()å®Ÿè£… | ğŸŸ¡ P1 | 2æ—¥ |
| REQ-ERR-2 | Partial Failure Tolerance | âŒ ãªã— | FallbackStrategyå®Ÿè£… | ğŸŸ¡ P1 | 2æ—¥ |
| REQ-ERR-3 | Circuit Breaker | âŒ ãªã— | CircuitBreakerå®Ÿè£… | ğŸŸ¡ P1 | 2æ—¥ |

**Phase 1 Gapç·è¨ˆ**: 6æ—¥

**è©³ç´°Gap**:

#### REQ-ERR-1: Retry Policy

**ç¾çŠ¶**:
```rust
// crates/miyabi-core/src/ ã«ã¯å­˜åœ¨ã—ãªã„
```

**å¿…è¦ãªå®Ÿè£…**:
```rust
// crates/miyabi-core/src/error_policy.rs (æ–°è¦)
pub struct RetryConfig {
    pub max_attempts: usize,       // 3
    pub base_delay: Duration,      // 1s
    pub max_delay: Duration,       // 60s
    pub backoff_multiplier: f64,   // 2.0
}

pub async fn retry_with_backoff<F, T, E>(
    config: &RetryConfig,
    mut operation: F,
) -> Result<T, E>
where
    F: FnMut() -> Pin<Box<dyn Future<Output = Result<T, E>>>>,
{
    let mut attempt = 0;
    let mut delay = config.base_delay;

    loop {
        attempt += 1;
        match operation().await {
            Ok(result) => return Ok(result),
            Err(err) if attempt >= config.max_attempts => return Err(err),
            Err(_) => {
                tokio::time::sleep(delay).await;
                delay = (delay * config.backoff_multiplier as u32).min(config.max_delay);
            }
        }
    }
}
```

**å—å…¥æ¡ä»¶**:
- [ ] 3å›ã¾ã§ãƒªãƒˆãƒ©ã‚¤
- [ ] å¾…æ©Ÿæ™‚é–“: 1s â†’ 2s â†’ 4s
- [ ] æœ€å¤§60ç§’ã‚’è¶…ãˆãªã„

---

#### REQ-ERR-2: Partial Failure Tolerance

**ç¾çŠ¶**:
```diff
- 1ã¤ã®WorldãŒå¤±æ•—ã—ãŸã‚‰å…¨ä½“å¤±æ•—
```

**å¿…è¦ãªå®Ÿè£…**:
```rust
#[derive(Debug, Clone)]
pub enum FallbackStrategy {
    AcceptPartialSuccess { min_successful_worlds: usize },  // 1/5ã§OK
    RetryWithLowerTemperature { temperature_reduction: f64 },
    SwitchModel { fallback_model: String },
    WaitForHumanIntervention { timeout: Duration },
    SkipTask,
}

pub async fn handle_partial_failure(
    results: Vec<Result<WorldResult>>,
    strategy: FallbackStrategy,
) -> Result<WorldResult> {
    match strategy {
        FallbackStrategy::AcceptPartialSuccess { min_successful_worlds } => {
            let successful = results.iter().filter(|r| r.is_ok()).count();
            if successful >= min_successful_worlds {
                // æˆåŠŸã—ãŸWorldã®ä¸­ã‹ã‚‰æœ€è‰¯ã‚’é¸æŠ
                Ok(select_best_world(results)?)
            } else {
                Err(anyhow!("Not enough successful worlds"))
            }
        }
        // ... ä»–ã®æˆ¦ç•¥
    }
}
```

**å—å…¥æ¡ä»¶**:
- [ ] 5ã¤ä¸­1ã¤ã§ã‚‚æˆåŠŸã™ã‚Œã°ç¶™ç¶š
- [ ] å…¨å¤±æ•—æ™‚ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æˆ¦ç•¥é©ç”¨
- [ ] æ¸©åº¦ã‚’ä¸‹ã’ã¦å†è©¦è¡Œå¯èƒ½

---

#### REQ-ERR-3: Circuit Breaker

**ç¾çŠ¶**:
```diff
- ã‚µãƒ¼ã‚­ãƒƒãƒˆãƒ–ãƒ¬ãƒ¼ã‚«ãƒ¼æ©Ÿæ§‹ãªã—
```

**å¿…è¦ãªå®Ÿè£…**:
```rust
pub struct CircuitBreaker {
    failure_threshold: usize,          // 5å›
    success_threshold: usize,          // 2å›
    timeout: Duration,                 // 60ç§’
    state: Arc<Mutex<CircuitState>>,
    consecutive_failures: Arc<Mutex<usize>>,
    consecutive_successes: Arc<Mutex<usize>>,
}

#[derive(Debug, Clone, Copy, PartialEq)]
pub enum CircuitState {
    Closed,    // æ­£å¸¸
    Open,      // é®æ–­
    HalfOpen,  // ãƒ†ã‚¹ãƒˆ
}

impl CircuitBreaker {
    pub async fn call<F, T>(&self, operation: F) -> Result<T>
    where
        F: Future<Output = Result<T>>,
    {
        match *self.state.lock().await {
            CircuitState::Open => {
                // ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆçµŒéå¾Œã«HalfOpenã¸
                if self.should_attempt_reset().await {
                    *self.state.lock().await = CircuitState::HalfOpen;
                } else {
                    return Err(anyhow!("Circuit breaker is open"));
                }
            }
            _ => {}
        }

        match operation.await {
            Ok(result) => {
                self.on_success().await;
                Ok(result)
            }
            Err(err) => {
                self.on_failure().await;
                Err(err)
            }
        }
    }

    async fn on_failure(&self) {
        let mut failures = self.consecutive_failures.lock().await;
        *failures += 1;
        *self.consecutive_successes.lock().await = 0;

        if *failures >= self.failure_threshold {
            *self.state.lock().await = CircuitState::Open;
            tracing::warn!("Circuit breaker opened after {} failures", failures);
        }
    }

    async fn on_success(&self) {
        let mut successes = self.consecutive_successes.lock().await;
        *successes += 1;
        *self.consecutive_failures.lock().await = 0;

        if *successes >= self.success_threshold {
            *self.state.lock().await = CircuitState::Closed;
            tracing::info!("Circuit breaker closed after {} successes", successes);
        }
    }
}
```

**å—å…¥æ¡ä»¶**:
- [ ] 5å›é€£ç¶šå¤±æ•—ã§é–‹ã
- [ ] 60ç§’å¾Œã«åŠé–‹çŠ¶æ…‹ã¸
- [ ] 2å›é€£ç¶šæˆåŠŸã§é–‰ã˜ã‚‹

---

### Phase 2: Resource Constraints and Scaling

| è¦ä»¶ID | è¦ä»¶ | ç¾çŠ¶ | Gap | å„ªå…ˆåº¦ | å·¥æ•° |
|--------|------|------|-----|--------|------|
| REQ-RES-1 | Hardware Limitsæ¤œå‡º | âŒ ãªã— | HardwareLimits::detect()å®Ÿè£… | ğŸŸ¡ P1 | 2æ—¥ |
| REQ-RES-2 | Dynamic Scaling | âŒ ãªã— | DynamicScalerå®Ÿè£… | ğŸŸ¡ P1 | 3æ—¥ |
| REQ-RES-3 | LLM Rate Limiting | âŒ ãªã— | RateLimiterå®Ÿè£… | ğŸŸ  P2 | 3æ—¥ |

**Phase 2 Gapç·è¨ˆ**: 8æ—¥

**è©³ç´°Gap**:

#### REQ-RES-1: Hardware Limits

**ç¾çŠ¶**:
```diff
- ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢åˆ¶ç´„ã®è‡ªå‹•æ¤œå‡ºãªã—
- ä¸¦åˆ—åº¦ã¯å›ºå®šå€¤
```

**å¿…è¦ãªå®Ÿè£…**:
```rust
// crates/miyabi-core/src/resource_limits.rs (æ–°è¦)
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct HardwareLimits {
    pub total_memory_gb: usize,
    pub total_cpu_cores: usize,
    pub total_disk_gb: usize,
}

impl HardwareLimits {
    pub fn detect() -> Result<Self> {
        use sysinfo::{System, SystemExt};
        let mut sys = System::new_all();
        sys.refresh_all();

        Ok(Self {
            total_memory_gb: (sys.total_memory() / 1024 / 1024 / 1024) as usize,
            total_cpu_cores: sys.cpus().len(),
            total_disk_gb: Self::get_disk_total()?,
        })
    }

    pub fn max_concurrent_worktrees(&self, per_worktree: &PerWorktreeLimits) -> usize {
        let memory_limit = self.total_memory_gb / per_worktree.memory_gb;
        let cpu_limit = self.total_cpu_cores / per_worktree.cpu_threads;
        let disk_limit = self.total_disk_gb / per_worktree.disk_gb;

        memory_limit.min(cpu_limit).min(disk_limit)
    }
}
```

**ä¾å­˜é–¢ä¿‚è¿½åŠ **:
```toml
# Cargo.toml
[workspace.dependencies]
sysinfo = "0.30"
```

**å—å…¥æ¡ä»¶**:
- [ ] ã‚·ã‚¹ãƒ†ãƒ ã‹ã‚‰æ­£ç¢ºã«ãƒ¡ãƒ¢ãƒªã€CPUã€ãƒ‡ã‚£ã‚¹ã‚¯ã‚’æ¤œå‡º
- [ ] max_concurrent_worktrees()ãŒæ­£ã—ãè¨ˆç®—ã•ã‚Œã‚‹
- [ ] æƒ³å®šç’°å¢ƒ(32GB, 8cores, 500GB)ã§4ã‚’è¿”ã™

---

#### REQ-RES-2: Dynamic Scaling

**ç¾çŠ¶**:
```diff
- ãƒªã‚½ãƒ¼ã‚¹ç›£è¦–ãªã—
- ä¸¦åˆ—åº¦ã®å‹•çš„èª¿æ•´ãªã—
```

**å¿…è¦ãªå®Ÿè£…**:
```rust
// crates/miyabi-orchestrator/src/dynamic_scaling.rs (æ–°è¦)
pub struct DynamicScaler {
    resource_monitor: ResourceMonitor,
    current_parallelism: Arc<Mutex<usize>>,
    max_parallelism: usize,
}

impl DynamicScaler {
    pub async fn adjust_parallelism(&self) -> usize {
        let usage = self.resource_monitor.get_current_usage().await;
        let mut parallelism = self.current_parallelism.lock().await;

        // ã‚¹ã‚±ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³
        if usage.memory_percent > 90.0 || usage.cpu_percent > 95.0 || usage.disk_percent > 85.0 {
            *parallelism = (*parallelism - 1).max(1);
            tracing::warn!(
                "Scaling down to {} due to resource pressure: mem={:.1}%, cpu={:.1}%, disk={:.1}%",
                *parallelism, usage.memory_percent, usage.cpu_percent, usage.disk_percent
            );
        }
        // ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—
        else if usage.memory_percent < 70.0 && usage.cpu_percent < 75.0 && usage.disk_percent < 70.0 {
            *parallelism = (*parallelism + 1).min(self.max_parallelism);
            tracing::info!("Scaling up to {}", *parallelism);
        }

        *parallelism
    }

    pub async fn monitor_loop(&self) {
        let mut interval = tokio::time::interval(Duration::from_secs(10));
        loop {
            interval.tick().await;
            self.adjust_parallelism().await;
        }
    }
}

pub struct ResourceMonitor {
    system: Arc<Mutex<System>>,
}

impl ResourceMonitor {
    pub async fn get_current_usage(&self) -> ResourceUsage {
        let mut sys = self.system.lock().await;
        sys.refresh_memory();
        sys.refresh_cpu();

        ResourceUsage {
            memory_percent: (sys.used_memory() as f64 / sys.total_memory() as f64) * 100.0,
            cpu_percent: sys.global_cpu_info().cpu_usage() as f64,
            disk_percent: Self::get_disk_usage_percent(),
        }
    }
}
```

**å—å…¥æ¡ä»¶**:
- [ ] 10ç§’ã”ã¨ã«ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨ç‡ã‚’ç›£è¦–
- [ ] ãƒ¡ãƒ¢ãƒª90%è¶…éæ™‚ã«ã‚¹ã‚±ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³
- [ ] CPU95%è¶…éæ™‚ã«ã‚¹ã‚±ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³
- [ ] ãƒªã‚½ãƒ¼ã‚¹ä½™è£•æ™‚ã«ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—

---

#### REQ-RES-3: LLM Rate Limiting

**ç¾çŠ¶**:
```diff
- Rate Limitingãªã—
- APIåˆ¶é™è¶…éã®å¯èƒ½æ€§
```

**å¿…è¦ãªå®Ÿè£…**:
```rust
// crates/miyabi-llm/src/rate_limiter.rs (æ–°è¦)
pub struct RateLimiter {
    requests_per_minute: usize,        // 50
    tokens_per_minute: usize,          // 40,000
    request_history: Arc<Mutex<VecDeque<Instant>>>,
    token_history: Arc<Mutex<VecDeque<(Instant, usize)>>>,
}

impl RateLimiter {
    pub async fn acquire_permit(&self, estimated_tokens: usize) -> Result<()> {
        loop {
            let now = Instant::now();
            let one_minute_ago = now - Duration::from_secs(60);

            // å¤ã„ã‚¨ãƒ³ãƒˆãƒªãƒ¼å‰Šé™¤
            {
                let mut requests = self.request_history.lock().await;
                while requests.front().map_or(false, |t| *t < one_minute_ago) {
                    requests.pop_front();
                }

                let mut tokens = self.token_history.lock().await;
                while tokens.front().map_or(false, |(t, _)| *t < one_minute_ago) {
                    tokens.pop_front();
                }
            }

            // ç¾åœ¨ã®ä½¿ç”¨çŠ¶æ³ç¢ºèª
            let current_requests = self.request_history.lock().await.len();
            let current_tokens: usize = self.token_history.lock().await
                .iter()
                .map(|(_, t)| t)
                .sum();

            // åˆ¶é™å†…ãªã‚‰è¨±å¯
            if current_requests < self.requests_per_minute
                && current_tokens + estimated_tokens < self.tokens_per_minute
            {
                self.request_history.lock().await.push_back(now);
                self.token_history.lock().await.push_back((now, estimated_tokens));
                return Ok(());
            }

            // åˆ¶é™è¶…éã®å ´åˆã¯å¾…æ©Ÿ
            tokio::time::sleep(Duration::from_millis(100)).await;
        }
    }
}
```

**å—å…¥æ¡ä»¶**:
- [ ] 1åˆ†é–“ã«50ãƒªã‚¯ã‚¨ã‚¹ãƒˆã¾ã§åˆ¶é™
- [ ] 1åˆ†é–“ã«40,000ãƒˆãƒ¼ã‚¯ãƒ³ã¾ã§åˆ¶é™
- [ ] ã‚¹ãƒ©ã‚¤ãƒ‡ã‚£ãƒ³ã‚°ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã§æ­£ç¢ºã«ç®¡ç†
- [ ] åˆ¶é™è¶…éæ™‚ã«è‡ªå‹•å¾…æ©Ÿ

---

### Phase 3: State Persistence and Recovery

| è¦ä»¶ID | è¦ä»¶ | ç¾çŠ¶ | Gap | å„ªå…ˆåº¦ | å·¥æ•° |
|--------|------|------|-----|--------|------|
| REQ-PER-1 | SQLiteãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ | âŒ ãªã— | å…¨ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ | ğŸŸ  P2 | 3æ—¥ |
| REQ-PER-2 | Checkpoint System | âŒ ãªã— | CheckpointManagerå®Ÿè£… | ğŸŸ  P2 | 3æ—¥ |
| REQ-PER-3 | Recovery System | âŒ ãªã— | RecoveryManagerå®Ÿè£… | ğŸŸ  P2 | 2æ—¥ |
| REQ-PER-4 | Garbage Collection | âŒ ãªã— | GarbageCollectorå®Ÿè£… | ğŸŸ¢ P3 | 2æ—¥ |

**Phase 3 Gapç·è¨ˆ**: 10æ—¥

**è©³ç´°Gap**:

#### REQ-PER-1: Database Schema

**ç¾çŠ¶**:
```diff
- SQLiteçµ±åˆãªã—
- æ°¸ç¶šåŒ–ãªã—
```

**å¿…è¦ãªå®Ÿè£…**:
```rust
// crates/miyabi-persistence/src/schema.rs (æ–°è¦crate)
pub const SCHEMA_SQL: &str = r#"
CREATE TABLE IF NOT EXISTS execution_runs (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    issue_number INTEGER NOT NULL,
    status TEXT NOT NULL,
    started_at TIMESTAMP NOT NULL,
    completed_at TIMESTAMP,
    total_cost_usd REAL DEFAULT 0.0,
    winning_world_id TEXT,
    final_score REAL
);

CREATE TABLE IF NOT EXISTS task_executions (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    run_id INTEGER NOT NULL,
    task_name TEXT NOT NULL,
    status TEXT NOT NULL,
    started_at TIMESTAMP NOT NULL,
    completed_at TIMESTAMP,
    FOREIGN KEY (run_id) REFERENCES execution_runs(id)
);

CREATE TABLE IF NOT EXISTS world_executions (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    task_id INTEGER NOT NULL,
    world_id TEXT NOT NULL,
    worktree_path TEXT NOT NULL,
    branch_name TEXT NOT NULL,
    status TEXT NOT NULL,
    started_at TIMESTAMP NOT NULL,
    completed_at TIMESTAMP,
    evaluation_score REAL,
    cost_usd REAL DEFAULT 0.0,
    FOREIGN KEY (task_id) REFERENCES task_executions(id)
);

CREATE TABLE IF NOT EXISTS checkpoints (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    run_id INTEGER NOT NULL,
    checkpoint_type TEXT NOT NULL,
    world_id TEXT,
    data JSON NOT NULL,
    created_at TIMESTAMP NOT NULL,
    FOREIGN KEY (run_id) REFERENCES execution_runs(id)
);

CREATE TABLE IF NOT EXISTS worktrees (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    world_id TEXT NOT NULL,
    path TEXT NOT NULL,
    branch TEXT NOT NULL,
    created_at TIMESTAMP NOT NULL,
    last_accessed_at TIMESTAMP NOT NULL,
    is_orphaned BOOLEAN DEFAULT 0
);

CREATE INDEX IF NOT EXISTS idx_checkpoints_run_id ON checkpoints(run_id);
CREATE INDEX IF NOT EXISTS idx_checkpoints_type ON checkpoints(checkpoint_type);
CREATE INDEX IF NOT EXISTS idx_worktrees_last_accessed ON worktrees(last_accessed_at);
"#;
```

**ä¾å­˜é–¢ä¿‚**:
```toml
# crates/miyabi-persistence/Cargo.toml
[dependencies]
sqlx = { version = "0.8", features = ["runtime-tokio-rustls", "sqlite", "chrono", "json"] }
```

**å—å…¥æ¡ä»¶**:
- [ ] SQLiteãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒæ­£å¸¸ã«ä½œæˆã•ã‚Œã‚‹
- [ ] 5ãƒ†ãƒ¼ãƒ–ãƒ«ãŒå…¨ã¦ä½œæˆã•ã‚Œã‚‹
- [ ] å¤–éƒ¨ã‚­ãƒ¼åˆ¶ç´„ãŒå‹•ä½œã™ã‚‹
- [ ] ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒé©ç”¨ã•ã‚Œã‚‹

---

#### REQ-PER-2: Checkpoint System

**ç¾çŠ¶**:
```diff
- ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆæ©Ÿæ§‹ãªã—
- ã‚¯ãƒ©ãƒƒã‚·ãƒ¥æ™‚ã®å¾©æ—§ä¸å¯
```

**å¿…è¦ãªå®Ÿè£…**:
```rust
// crates/miyabi-persistence/src/checkpoint.rs
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum CheckpointType {
    WorktreeCreated {
        world_id: WorldId,
        path: PathBuf,
        branch: String,
    },
    WorldsSpawned {
        task_id: i64,
        world_ids: Vec<WorldId>,
    },
    WorldCompleted {
        world_id: WorldId,
        score: f64,
        artifacts: Vec<PathBuf>,
    },
    EvaluationDone {
        winning_world: WorldId,
        all_scores: HashMap<WorldId, f64>,
    },
    MergeReady {
        winning_world: WorldId,
        pr_number: Option<u64>,
    },
}

pub struct CheckpointManager {
    db: Arc<SqlitePool>,
    interval: Duration,  // 5åˆ†
}

impl CheckpointManager {
    pub async fn save_checkpoint(
        &self,
        run_id: i64,
        checkpoint: CheckpointType,
    ) -> Result<()> {
        let data = serde_json::to_string(&checkpoint)?;
        let checkpoint_type_str = checkpoint.type_name();
        let world_id = checkpoint.world_id();

        sqlx::query!(
            "INSERT INTO checkpoints (run_id, checkpoint_type, world_id, data, created_at)
             VALUES (?, ?, ?, ?, ?)",
            run_id,
            checkpoint_type_str,
            world_id,
            data,
            Utc::now()
        )
        .execute(&*self.db)
        .await?;

        Ok(())
    }

    pub async fn auto_checkpoint_loop(&self, run_id: i64) {
        let mut interval = tokio::time::interval(self.interval);
        loop {
            interval.tick().await;
            if let Err(e) = self.checkpoint_current_state(run_id).await {
                tracing::error!("Auto checkpoint failed: {}", e);
            }
        }
    }
}
```

**å—å…¥æ¡ä»¶**:
- [ ] 5åˆ†ã”ã¨ã«è‡ªå‹•ä¿å­˜ã•ã‚Œã‚‹
- [ ] 5ç¨®é¡ã®CheckpointTypeãŒå…¨ã¦ã‚µãƒãƒ¼ãƒˆã•ã‚Œã‚‹
- [ ] JSONå½¢å¼ã§ãƒ‡ãƒ¼ã‚¿ãŒä¿å­˜ã•ã‚Œã‚‹

---

### Phase 4: Security Model

| è¦ä»¶ID | è¦ä»¶ | ç¾çŠ¶ | Gap | å„ªå…ˆåº¦ | å·¥æ•° |
|--------|------|------|-----|--------|------|
| REQ-SEC-1 | Threat Model | âŒ ãªã— | è„…å¨å®šç¾© | ğŸŸ  P2 | 1æ—¥ |
| REQ-SEC-2 | Static Analysis | âŒ ãªã— | 5ç¨®é¡ã®è§£æå®Ÿè£… | ğŸŸ  P2 | 4æ—¥ |
| REQ-SEC-3 | Container Isolation | âŒ ãªã— | Dockeråˆ†é›¢å®Ÿè£… | ğŸŸ¢ P3 | 2æ—¥ |
| REQ-SEC-4 | Runtime Monitoring | âŒ ãªã— | ç›£è¦–å®Ÿè£… | ğŸŸ¢ P3 | 2æ—¥ |

**Phase 4 Gapç·è¨ˆ**: 9æ—¥

---

### Phase 5: Observability

| è¦ä»¶ID | è¦ä»¶ | ç¾çŠ¶ | Gap | å„ªå…ˆåº¦ | å·¥æ•° |
|--------|------|------|-----|--------|------|
| REQ-OBS-1 | Structured Logging | ğŸŸ¡ éƒ¨åˆ†çš„ | éšå±¤ãƒ­ã‚¬ãƒ¼å®Ÿè£… | ğŸŸ  P2 | 2æ—¥ |
| REQ-OBS-2 | Prometheus Metrics | âŒ ãªã— | 20+ãƒ¡ãƒˆãƒªã‚¯ã‚¹å®Ÿè£… | ğŸŸ  P2 | 3æ—¥ |
| REQ-OBS-3 | Distributed Tracing | âŒ ãªã— | OpenTelemetryçµ±åˆ | ğŸŸ¢ P3 | 3æ—¥ |
| REQ-OBS-4 | Grafana Dashboard | âŒ ãªã— | ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰å®šç¾© | ğŸŸ¢ P3 | 1æ—¥ |

**Phase 5 Gapç·è¨ˆ**: 9æ—¥

---

### Phase 6: Cost Optimization

| è¦ä»¶ID | è¦ä»¶ | ç¾çŠ¶ | Gap | å„ªå…ˆåº¦ | å·¥æ•° |
|--------|------|------|-----|--------|------|
| REQ-COST-1 | Budget Management | âŒ ãªã— | äºˆç®—è¨­å®š | ğŸŸ  P2 | 1æ—¥ |
| REQ-COST-2 | Cost Tracking | âŒ ãªã— | ã‚³ã‚¹ãƒˆè¨ˆç®—å®Ÿè£… | ğŸŸ  P2 | 2æ—¥ |
| REQ-COST-3 | Early Termination | âŒ ãªã— | æ‰“ã¡åˆ‡ã‚Šãƒãƒªã‚·ãƒ¼å®Ÿè£… | ğŸŸ¡ P1 | 2æ—¥ |
| REQ-COST-4 | Response Caching | âŒ ãªã— | LRUã‚­ãƒ£ãƒƒã‚·ãƒ¥å®Ÿè£… | ğŸŸ  P2 | 2æ—¥ |
| REQ-COST-5 | Model Selection | âŒ ãªã— | è¤‡é›‘åº¦ãƒ™ãƒ¼ã‚¹é¸æŠå®Ÿè£… | ğŸŸ¢ P3 | 2æ—¥ |

**Phase 6 Gapç·è¨ˆ**: 9æ—¥

---

## ğŸ“Š Overall Gap Summary

### å®Ÿè£…Gapç·è¨ˆ

| Phase | å·¥æ•° | å„ªå…ˆåº¦åˆ†å¸ƒ | æ–°è¦Crate |
|-------|------|-----------|----------|
| Phase 0 | å®Œäº† | - | - |
| Phase 1 | 6æ—¥ | P1Ã—3 | ãªã—ï¼ˆæ‹¡å¼µã®ã¿ï¼‰ |
| Phase 2 | 8æ—¥ | P1Ã—2, P2Ã—1 | ãªã—ï¼ˆæ‹¡å¼µã®ã¿ï¼‰ |
| Phase 3 | 10æ—¥ | P2Ã—3, P3Ã—1 | 3å€‹ |
| Phase 4 | 9æ—¥ | P2Ã—2, P3Ã—2 | 1å€‹ |
| Phase 5 | 9æ—¥ | P2Ã—2, P3Ã—2 | 1å€‹ |
| Phase 6 | 9æ—¥ | P1Ã—1, P2Ã—3, P3Ã—1 | 1å€‹ |
| **åˆè¨ˆ** | **51æ—¥** | **P0Ã—2, P1Ã—6, P2Ã—13, P3Ã—7** | **6å€‹** |

### å„ªå…ˆåº¦åˆ¥å®Ÿè£…é †åº

#### ğŸ”´ P0 (Critical) - 2é …ç›®

1. **5-Worlds Strategy** (CR-1)
   - WorldIdå‹å®šç¾©
   - FiveWorldsManager
   - EvaluationScore
   - å·¥æ•°: 7-10æ—¥

2. **Worktree Isolation** (CR-2)
   - 5-Worldså¯¾å¿œWorktreeç®¡ç†
   - å·¥æ•°: 3-5æ—¥

**P0åˆè¨ˆ**: 10-15æ—¥

---

#### ğŸŸ¡ P1 (High) - 6é …ç›®

1. REQ-ERR-1: Retry Policy (2æ—¥)
2. REQ-ERR-2: Partial Failure (2æ—¥)
3. REQ-ERR-3: Circuit Breaker (2æ—¥)
4. REQ-RES-1: Hardware Limits (2æ—¥)
5. REQ-RES-2: Dynamic Scaling (3æ—¥)
6. REQ-COST-3: Early Termination (2æ—¥)

**P1åˆè¨ˆ**: 13æ—¥

---

#### ğŸŸ  P2 (Medium) - 13é …ç›®

Phase 2-6ã®å¤§éƒ¨åˆ†

**P2åˆè¨ˆ**: 23æ—¥

---

#### ğŸŸ¢ P3 (Low) - 7é …ç›®

Observabilityã¨Securityã®ä¸€éƒ¨

**P3åˆè¨ˆ**: 14æ—¥

---

## ğŸ¯ Recommended Implementation Order

### Week 1: P0 Core Foundation

**ç›®æ¨™**: 5-Worldsæˆ¦ç•¥ã®åŸºç›¤å®Ÿè£…

```
Day 1-2: miyabi-typesæ‹¡å¼µ (WorldId, WorldConfig, EvaluationScore)
Day 3-4: miyabi-worktreeæ‹¡å¼µ (FiveWorldsManager)
Day 5-7: miyabi-orchestratoræ‹¡å¼µ (FiveWorldsExecutoréª¨çµ„ã¿)
```

**æˆæœç‰©**:
- WorldIdå‹ãŒä½¿ç”¨å¯èƒ½
- 5ã¤ã®WorktreeãŒä½œæˆå¯èƒ½
- åŸºæœ¬çš„ãªä¸¦åˆ—å®Ÿè¡ŒãŒå‹•ä½œ

---

### Week 2: P1 Error Handling & Scaling

**ç›®æ¨™**: ã‚¨ãƒ©ãƒ¼å‡¦ç†ã¨å‹•çš„ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å®Ÿè£…

```
Day 1-2: miyabi-coreæ‹¡å¼µ (RetryConfig, retry_with_backoff)
Day 3-4: miyabi-coreæ‹¡å¼µ (CircuitBreaker, FallbackStrategy)
Day 5-6: miyabi-coreæ‹¡å¼µ (HardwareLimits, ResourceMonitor)
Day 7: miyabi-orchestratoræ‹¡å¼µ (DynamicScaler)
```

**æˆæœç‰©**:
- ãƒªãƒˆãƒ©ã‚¤æ©Ÿæ§‹ãŒå‹•ä½œ
- ã‚µãƒ¼ã‚­ãƒƒãƒˆãƒ–ãƒ¬ãƒ¼ã‚«ãƒ¼ãŒå‹•ä½œ
- ãƒªã‚½ãƒ¼ã‚¹ç›£è¦–ãŒå‹•ä½œ
- å‹•çš„ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãŒå‹•ä½œ

---

### Week 3: P1+P2 LLM & Cost (Part 1)

**ç›®æ¨™**: LLMæœ€é©åŒ–ã¨ã‚³ã‚¹ãƒˆç®¡ç†åŸºç›¤

```
Day 1-2: miyabi-llmæ‹¡å¼µ (RateLimiter)
Day 3-4: miyabi-llmæ‹¡å¼µ (LlmResponseCache)
Day 5-7: miyabi-costæ–°è¦ (CostTracker, EarlyTerminationPolicy)
```

**æˆæœç‰©**:
- Rate Limitingå‹•ä½œ
- Cacheãƒ’ãƒƒãƒˆç‡æ¸¬å®šå¯èƒ½
- ã‚³ã‚¹ãƒˆè¿½è·¡ãŒå‹•ä½œ
- æ—©æœŸæ‰“ã¡åˆ‡ã‚ŠãŒå‹•ä½œ

---

### Week 4: P2 Persistence

**ç›®æ¨™**: æ°¸ç¶šåŒ–ã¨å¾©æ—§ã‚·ã‚¹ãƒ†ãƒ å®Ÿè£…

```
Day 1-3: miyabi-persistenceæ–°è¦ (SQLite, CheckpointManager)
Day 4-5: miyabi-recoveryæ–°è¦ (RecoveryManager)
Day 6-7: miyabi-gcæ–°è¦ (GarbageCollector)
```

**æˆæœç‰©**:
- SQLiteãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒå‹•ä½œ
- 5åˆ†ã”ã¨ã«ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜
- ã‚¯ãƒ©ãƒƒã‚·ãƒ¥å¾Œã®å¾©æ—§ãŒå¯èƒ½
- å­¤å…WorktreeãŒè‡ªå‹•å‰Šé™¤

---

### Week 5: P2 Security

**ç›®æ¨™**: ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å±¤å®Ÿè£…

```
Day 1: miyabi-securityæ–°è¦ (Threat Model)
Day 2-4: miyabi-securityæ‹¡å¼µ (StaticAnalyzer - 5ç¨®é¡)
Day 5-6: miyabi-securityæ‹¡å¼µ (IsolationManager - Docker)
Day 7: miyabi-securityæ‹¡å¼µ (RuntimeMonitor)
```

**æˆæœç‰©**:
- é™çš„è§£æãŒå‹•ä½œ
- Dockeråˆ†é›¢ãŒå‹•ä½œ
- ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒªã‚¹ã‚¯æ¤œå‡º

---

### Week 6: P2+P3 Observability

**ç›®æ¨™**: è¦³æ¸¬å¯èƒ½æ€§å®Ÿè£…

```
Day 1-2: miyabi-observabilityæ–°è¦ (IssueLogger, TaskLogger, WorldLogger)
Day 3-4: miyabi-observabilityæ‹¡å¼µ (Prometheus Metrics - 20+å€‹)
Day 5-6: miyabi-observabilityæ‹¡å¼µ (OpenTelemetry Tracing)
Day 7: miyabi-observabilityæ‹¡å¼µ (Grafana Dashboard)
```

**æˆæœç‰©**:
- JSONæ§‹é€ åŒ–ãƒ­ã‚°
- Prometheusãƒ¡ãƒˆãƒªã‚¯ã‚¹å…¬é–‹
- åˆ†æ•£ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°å‹•ä½œ
- Grafanaãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰è¡¨ç¤º

---

### Week 7: P3 Cost & Integration

**ç›®æ¨™**: ã‚³ã‚¹ãƒˆæœ€é©åŒ–å®Œæˆã¨Agentçµ±åˆ

```
Day 1-2: miyabi-costæ‹¡å¼µ (ModelSelector, BudgetManager)
Day 3-4: miyabi-agent-coordinatorçµ±åˆ (FiveWorldsExecutorçµ±åˆ)
Day 5-6: miyabi-agent-reviewçµ±åˆ (EvaluationScoreçµ±åˆ)
Day 7: miyabi-cliæ‹¡å¼µ (parallel ã‚µãƒ–ã‚³ãƒãƒ³ãƒ‰)
```

**æˆæœç‰©**:
- ãƒ¢ãƒ‡ãƒ«é¸æŠãŒå‹•ä½œ
- æœˆé¡äºˆç®—ç®¡ç†ãŒå‹•ä½œ
- CoordinatorAgentãŒ5-Worldsä½¿ç”¨
- `miyabi parallel`ã‚³ãƒãƒ³ãƒ‰ãŒå‹•ä½œ

---

### Week 8: Testing & Validation

**ç›®æ¨™**: çµ±åˆãƒ†ã‚¹ãƒˆã€E2Eã€ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯

```
Day 1-3: çµ±åˆãƒ†ã‚¹ãƒˆå®Ÿè£…
Day 4-5: E2Eãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
Day 6-7: ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆ & æ€§èƒ½ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°
```

**æˆæœç‰©**:
- å…¨çµ±åˆãƒ†ã‚¹ãƒˆãŒåˆæ ¼
- E2Eãƒ†ã‚¹ãƒˆãŒæˆåŠŸ
- ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœãŒç›®æ¨™å€¤å†…

---

## ğŸ“ˆ Success Metrics

### å®Ÿè£…å®Œäº†åŸºæº–

#### Phase 1-2 å®Œäº†åŸºæº–

- [ ] WorldIdãŒ5ã¤ã®Worldã§å‹•ä½œ
- [ ] FiveWorldsManagerãŒ5ã¤ã®Worktreeã‚’ä¸¦åˆ—ä½œæˆ
- [ ] EvaluationScoreãŒ100ç‚¹æº€ç‚¹ã§è¨ˆç®—
- [ ] æœ€é«˜ã‚¹ã‚³ã‚¢ã®WorldãŒé¸æŠã•ã‚Œã‚‹
- [ ] ãƒªãƒˆãƒ©ã‚¤ãŒ3å›ã¾ã§å®Ÿè¡Œã•ã‚Œã‚‹
- [ ] ã‚µãƒ¼ã‚­ãƒƒãƒˆãƒ–ãƒ¬ãƒ¼ã‚«ãƒ¼ãŒ5å›é€£ç¶šå¤±æ•—ã§é–‹ã
- [ ] å‹•çš„ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãŒãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨ç‡ã«å¿œã˜ã¦èª¿æ•´

#### Phase 3-4 å®Œäº†åŸºæº–

- [ ] SQLiteãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒä½œæˆã•ã‚Œã‚‹
- [ ] 5åˆ†ã”ã¨ã«ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãŒä¿å­˜ã•ã‚Œã‚‹
- [ ] ã‚¯ãƒ©ãƒƒã‚·ãƒ¥å¾Œã«è‡ªå‹•å¾©æ—§ã§ãã‚‹
- [ ] 24æ™‚é–“å¾Œã«å­¤å…WorktreeãŒå‰Šé™¤ã•ã‚Œã‚‹
- [ ] é™çš„è§£æãŒ5ç¨®é¡å‹•ä½œã™ã‚‹
- [ ] Dockeråˆ†é›¢ãŒãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§æœ‰åŠ¹

#### Phase 5-6 å®Œäº†åŸºæº–

- [ ] JSONæ§‹é€ åŒ–ãƒ­ã‚°ãŒå‡ºåŠ›ã•ã‚Œã‚‹
- [ ] 20+å€‹ã®Prometheusãƒ¡ãƒˆãƒªã‚¯ã‚¹ãŒå…¬é–‹ã•ã‚Œã‚‹
- [ ] OpenTelemetryãƒˆãƒ¬ãƒ¼ã‚¹ãŒå‹•ä½œã™ã‚‹
- [ ] å…¨LLMå‘¼ã³å‡ºã—ã§ã‚³ã‚¹ãƒˆãŒè¨˜éŒ²ã•ã‚Œã‚‹
- [ ] ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡ãŒæ¸¬å®šå¯èƒ½
- [ ] æœˆé¡äºˆç®—ãŒç®¡ç†ã•ã‚Œã‚‹

#### ç·åˆå—å…¥åŸºæº–

- [ ] Issueå‡¦ç†æ™‚é–“ < 30åˆ†
- [ ] ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æˆåŠŸç‡ > 80%
- [ ] ãƒ†ã‚¹ãƒˆåˆæ ¼ç‡ > 70%
- [ ] è©•ä¾¡ã‚¹ã‚³ã‚¢å¹³å‡ > 70ç‚¹
- [ ] Issueå˜ä¾¡ < $5.00
- [ ] ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡ > 30%
- [ ] ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ < 90%
- [ ] CPUä½¿ç”¨ç‡ < 95%

---

## ğŸ”— Related Documents

- [SYSTEM_REQUIREMENTS_V2.md](SYSTEM_REQUIREMENTS_V2.md) - è¦ä»¶å®šç¾©
- [EXISTING_SYSTEM_ANALYSIS.md](EXISTING_SYSTEM_ANALYSIS.md) - æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ åˆ†æ
- [IMPLEMENTATION_ROADMAP.md](IMPLEMENTATION_ROADMAP.md) - å®Ÿè£…ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—

---

**Document Status**: âœ… Phase 0 - Complete
**Next Action**: Phase 1 é–‹å§‹ - Week 1 Day 1

**Analyzed by**: System Architect
**Date**: 2025-10-25
**Total Implementation Effort**: 51æ—¥ (ç´„10-11é€±é–“)

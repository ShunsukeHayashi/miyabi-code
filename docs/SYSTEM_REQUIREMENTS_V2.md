# Miyabi System Requirements Specification v2.0

**Document Version**: 2.0.0
**Last Updated**: 2025-10-25
**Status**: FINAL - Ready for Implementation

---

## ğŸ“‹ Executive Summary

æœ¬ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯ã€Miyabiè‡ªå¾‹å‹é–‹ç™ºãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã®å®Œå…¨ãªè¦ä»¶å®šç¾©æ›¸ã§ã™ã€‚6ã¤ã®è¨­è¨ˆãƒ•ã‚§ãƒ¼ã‚ºã‚’çµŒã¦ç¢ºå®šã—ãŸå…¨ä»•æ§˜ã‚’çµ±åˆã—ã¦ã„ã¾ã™ã€‚

**ã‚·ã‚¹ãƒ†ãƒ æ¦‚è¦**:
- **ç›®çš„**: GitHub Issueã‚’å…¥åŠ›ã¨ã—ã¦ã€ã‚³ãƒ¼ãƒ‰å®Ÿè£…ã‹ã‚‰PRä½œæˆã¾ã§å®Œå…¨è‡ªå‹•åŒ–
- **ã‚³ã‚¢æŠ€è¡“**: 5-Worldsä¸¦åˆ—å®Ÿè¡Œæˆ¦ç•¥ã«ã‚ˆã‚‹å“è³ªä¿è¨¼
- **å®Ÿè£…è¨€èª**: Rust 2021 Edition
- **ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£**: Git Worktreeä¸¦åˆ—åˆ†é›¢å®Ÿè¡Œ

---

## ğŸ¯ Core Requirements

### CR-1: 5-Worlds Quality Assurance Strategy

**å„ªå…ˆåº¦**: â­â­â­â­â­ (CRITICAL)

**è¦ä»¶**:
LLMã®ç¢ºç‡è«–çš„å‡ºåŠ›ç‰¹æ€§ã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã€å…¨ã¦ã®ã‚³ãƒ¼ãƒ‰ç”Ÿæˆã‚¿ã‚¹ã‚¯ã¯**å¿…ãš5ã¤ã®ãƒ‘ãƒ©ãƒ¬ãƒ«ãƒ¯ãƒ¼ãƒ«ãƒ‰ã§åŒæ™‚å®Ÿè¡Œ**ã—ã€è©•ä¾¡å¾Œã«æœ€è‰¯ã®1ã¤ã®ã¿ã‚’ç¾å®ŸåŒ–ã™ã‚‹ã€‚

**è©³ç´°ä»•æ§˜**:

```rust
// crates/miyabi-types/src/world.rs
#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]
pub enum WorldId {
    Alpha,   // ä¿å®ˆçš„ (T=0.3)
    Beta,    // ãƒãƒ©ãƒ³ã‚¹ (T=0.7)
    Gamma,   // å‰µé€ çš„ (T=1.2)
    Delta,   // ä»£æ›¿ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
    Epsilon, // ä»£æ›¿ãƒ¢ãƒ‡ãƒ«
}

pub struct WorldConfig {
    pub id: WorldId,
    pub model: String,
    pub temperature: f64,
    pub prompt_variant: PromptVariant,
    pub worktree_path: PathBuf,
}

impl Default for WorldConfig {
    fn default_for(id: WorldId) -> Self {
        match id {
            WorldId::Alpha => Self {
                id,
                model: "gpt-4o".into(),
                temperature: 0.3,
                prompt_variant: PromptVariant::Standard,
                worktree_path: PathBuf::from("worktrees/alpha"),
            },
            WorldId::Beta => Self {
                id,
                model: "gpt-4o".into(),
                temperature: 0.7,
                prompt_variant: PromptVariant::Standard,
                worktree_path: PathBuf::from("worktrees/beta"),
            },
            WorldId::Gamma => Self {
                id,
                model: "gpt-4o".into(),
                temperature: 1.2,
                prompt_variant: PromptVariant::Standard,
                worktree_path: PathBuf::from("worktrees/gamma"),
            },
            WorldId::Delta => Self {
                id,
                model: "gpt-4o".into(),
                temperature: 0.7,
                prompt_variant: PromptVariant::AlternativeA,
                worktree_path: PathBuf::from("worktrees/delta"),
            },
            WorldId::Epsilon => Self {
                id,
                model: "claude-3-5-sonnet".into(),
                temperature: 0.7,
                prompt_variant: PromptVariant::Standard,
                worktree_path: PathBuf::from("worktrees/epsilon"),
            },
        }
    }
}
```

**è©•ä¾¡åŸºæº–** (100ç‚¹æº€ç‚¹):
```rust
pub struct EvaluationScore {
    pub compilation_success: f64,      // 30ç‚¹: ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æˆåŠŸ=30, å¤±æ•—=0
    pub test_pass_rate: f64,           // 30ç‚¹: ãƒ†ã‚¹ãƒˆåˆæ ¼ç‡ Ã— 30
    pub clippy_score: f64,             // 20ç‚¹: (1 - warnings/100) Ã— 20
    pub code_quality: f64,             // 10ç‚¹: å¯èª­æ€§ãƒ»ä¿å®ˆæ€§
    pub security_score: f64,           // 10ç‚¹: ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£åˆ†æçµæœ
    pub total: f64,                    // åˆè¨ˆ100ç‚¹
}

impl EvaluationScore {
    pub fn calculate(world: &WorldExecution) -> Self {
        let compilation = if world.build_success { 30.0 } else { 0.0 };
        let tests = (world.tests_passed as f64 / world.tests_total.max(1) as f64) * 30.0;
        let clippy = (1.0 - (world.clippy_warnings as f64 / 100.0).min(1.0)) * 20.0;
        let quality = world.code_quality_metrics.overall_score * 10.0;
        let security = world.security_report.score * 10.0;

        Self {
            compilation_success: compilation,
            test_pass_rate: tests,
            clippy_score: clippy,
            code_quality: quality,
            security_score: security,
            total: compilation + tests + clippy + quality + security,
        }
    }
}
```

**å—å…¥æ¡ä»¶**:
- [ ] 5ã¤ã®WorldãŒç‹¬ç«‹ã—ãŸWorktreeã§ä¸¦åˆ—å®Ÿè¡Œã•ã‚Œã‚‹
- [ ] å„WorldãŒç•°ãªã‚‹LLMãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§å®Ÿè¡Œã•ã‚Œã‚‹
- [ ] è©•ä¾¡ã‚¹ã‚³ã‚¢ãŒæ­£ç¢ºã«è¨ˆç®—ã•ã‚Œã‚‹
- [ ] æœ€é«˜ã‚¹ã‚³ã‚¢ã®Worldã®ã¿ãŒmainãƒ–ãƒ©ãƒ³ãƒã«ãƒãƒ¼ã‚¸ã•ã‚Œã‚‹
- [ ] å¤±æ•—ã—ãŸWorldã¯è‡ªå‹•ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã•ã‚Œã‚‹

---

### CR-2: Git Worktree Isolation

**å„ªå…ˆåº¦**: â­â­â­â­â­ (CRITICAL)

**è¦ä»¶**:
å„Worldã¯å®Œå…¨ã«ç‹¬ç«‹ã—ãŸGit Worktreeã§å®Ÿè¡Œã•ã‚Œã€ç›¸äº’å¹²æ¸‰ã‚’é˜²ãã€‚

**è©³ç´°ä»•æ§˜**:

```rust
// crates/miyabi-worktree/src/manager.rs
pub struct WorktreeManager {
    base_path: PathBuf,
    active_worktrees: Arc<Mutex<HashMap<WorldId, WorktreeHandle>>>,
}

impl WorktreeManager {
    pub async fn create_worktree(
        &self,
        world_id: WorldId,
        issue_number: u64,
    ) -> Result<WorktreeHandle> {
        let branch_name = format!("world-{:?}-issue-{}", world_id, issue_number);
        let worktree_path = self.base_path.join(&branch_name);

        // Git worktreeä½œæˆ
        Command::new("git")
            .args(["worktree", "add", worktree_path.to_str().unwrap(), "-b", &branch_name])
            .output()
            .await?;

        let handle = WorktreeHandle {
            world_id,
            path: worktree_path,
            branch: branch_name,
            created_at: Utc::now(),
        };

        self.active_worktrees.lock().await.insert(world_id, handle.clone());

        Ok(handle)
    }

    pub async fn cleanup_worktree(&self, world_id: WorldId) -> Result<()> {
        if let Some(handle) = self.active_worktrees.lock().await.remove(&world_id) {
            // Worktreeå‰Šé™¤
            Command::new("git")
                .args(["worktree", "remove", "--force", handle.path.to_str().unwrap()])
                .output()
                .await?;

            // ãƒ–ãƒ©ãƒ³ãƒå‰Šé™¤
            Command::new("git")
                .args(["branch", "-D", &handle.branch])
                .output()
                .await?;
        }
        Ok(())
    }
}
```

**å—å…¥æ¡ä»¶**:
- [ ] å„WorldãŒç‹¬ç«‹ã—ãŸWorktreeã§å®Ÿè¡Œã•ã‚Œã‚‹
- [ ] Worktreeé–“ã§ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´ãŒå¹²æ¸‰ã—ãªã„
- [ ] å¤±æ•—æ™‚ã«è‡ªå‹•çš„ã«WorktreeãŒå‰Šé™¤ã•ã‚Œã‚‹
- [ ] æœ€å¤§åŒæ™‚Worktreeæ•°ãŒåˆ¶é™ã•ã‚Œã‚‹ (ãƒªã‚½ãƒ¼ã‚¹åˆ¶ç´„ã«å¾“ã†)

---

## ğŸ›¡ï¸ Phase 1: Error Handling Strategy

### REQ-ERR-1: Retry Policy

**è©³ç´°ä»•æ§˜**:

```rust
// crates/miyabi-core/src/error_policy.rs
#[derive(Debug, Clone)]
pub struct RetryConfig {
    pub max_attempts: usize,           // 3å›
    pub base_delay: Duration,          // 1ç§’
    pub max_delay: Duration,           // 60ç§’
    pub backoff_multiplier: f64,       // 2.0 (æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•)
}

impl Default for RetryConfig {
    fn default() -> Self {
        Self {
            max_attempts: 3,
            base_delay: Duration::from_secs(1),
            max_delay: Duration::from_secs(60),
            backoff_multiplier: 2.0,
        }
    }
}

pub async fn retry_with_backoff<F, T, E>(
    config: &RetryConfig,
    mut operation: F,
) -> Result<T, E>
where
    F: FnMut() -> Pin<Box<dyn Future<Output = Result<T, E>>>>,
{
    let mut attempt = 0;
    let mut delay = config.base_delay;

    loop {
        attempt += 1;

        match operation().await {
            Ok(result) => return Ok(result),
            Err(err) if attempt >= config.max_attempts => return Err(err),
            Err(_) => {
                tokio::time::sleep(delay).await;
                delay = (delay * config.backoff_multiplier as u32)
                    .min(config.max_delay);
            }
        }
    }
}
```

**å—å…¥æ¡ä»¶**:
- [ ] LLM APIå‘¼ã³å‡ºã—ãŒ3å›ã¾ã§ãƒªãƒˆãƒ©ã‚¤ã•ã‚Œã‚‹
- [ ] å¾…æ©Ÿæ™‚é–“ãŒæŒ‡æ•°çš„ã«å¢—åŠ ã™ã‚‹ (1s â†’ 2s â†’ 4s)
- [ ] æœ€å¤§60ç§’ã‚’è¶…ãˆãªã„

### REQ-ERR-2: Partial Failure Tolerance

**è©³ç´°ä»•æ§˜**:

```rust
pub enum FallbackStrategy {
    // 5ã¤ã®ã†ã¡1ã¤ãŒæˆåŠŸã™ã‚Œã°OK
    AcceptPartialSuccess {
        min_successful_worlds: usize  // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 1
    },

    // æ¸©åº¦ã‚’ä¸‹ã’ã¦å†å®Ÿè¡Œ
    RetryWithLowerTemperature {
        temperature_reduction: f64    // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: -0.2
    },

    // åˆ¥ã®ãƒ¢ãƒ‡ãƒ«ã«åˆ‡ã‚Šæ›¿ãˆ
    SwitchModel {
        fallback_model: String        // "claude-3-5-sonnet"
    },

    // äººé–“ã®ä»‹å…¥ã‚’å¾…ã¤
    WaitForHumanIntervention {
        timeout: Duration             // 24æ™‚é–“
    },

    // ã‚¿ã‚¹ã‚¯ã‚’ã‚¹ã‚­ãƒƒãƒ—
    SkipTask,
}
```

**å—å…¥æ¡ä»¶**:
- [ ] 5ã¤ã®Worldã®ã†ã¡1ã¤ã§ã‚‚æˆåŠŸã™ã‚Œã°å‡¦ç†ç¶šè¡Œ
- [ ] å…¨å¤±æ•—æ™‚ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æˆ¦ç•¥ãŒé©ç”¨ã•ã‚Œã‚‹
- [ ] ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æˆ¦ç•¥ã®é¸æŠãŒé©åˆ‡ã«è¡Œã‚ã‚Œã‚‹

### REQ-ERR-3: Circuit Breaker

**è©³ç´°ä»•æ§˜**:

```rust
pub struct CircuitBreaker {
    failure_threshold: usize,          // 5å›é€£ç¶šå¤±æ•—ã§OPEN
    success_threshold: usize,          // 2å›é€£ç¶šæˆåŠŸã§CLOSED
    timeout: Duration,                 // 60ç§’å¾Œã«HALF_OPEN
    state: Arc<Mutex<CircuitState>>,
    consecutive_failures: Arc<Mutex<usize>>,
    consecutive_successes: Arc<Mutex<usize>>,
}

#[derive(Debug, Clone, Copy, PartialEq)]
pub enum CircuitState {
    Closed,    // æ­£å¸¸å‹•ä½œ
    Open,      // é®æ–­ä¸­
    HalfOpen,  // ãƒ†ã‚¹ãƒˆä¸­
}
```

**å—å…¥æ¡ä»¶**:
- [ ] 5å›é€£ç¶šå¤±æ•—ã§ã‚µãƒ¼ã‚­ãƒƒãƒˆãƒ–ãƒ¬ãƒ¼ã‚«ãƒ¼ãŒé–‹ã
- [ ] 60ç§’å¾Œã«åŠé–‹çŠ¶æ…‹ã«ç§»è¡Œ
- [ ] 2å›é€£ç¶šæˆåŠŸã§æ­£å¸¸çŠ¶æ…‹ã«å¾©å¸°

---

## ğŸ’» Phase 2: Resource Constraints and Scaling

### REQ-RES-1: Hardware Limits

**è©³ç´°ä»•æ§˜**:

```toml
# config/resource_limits.toml
[hardware]
total_memory_gb = 32
total_cpu_cores = 8
total_disk_gb = 500

[per_worktree]
memory_gb = 2
cpu_threads = 2
disk_gb = 5

[calculated]
max_concurrent_worktrees = 4  # min(32/2, 8/2, 500/5) = 4
```

**ç‰©ç†åˆ¶ç´„**:
- ãƒ¡ãƒ¢ãƒªåˆ¶ç´„: 32GB / 2GB = 16 Worktrees
- CPUåˆ¶ç´„: 8 cores / 2 threads = 4 Worktrees â¬…ï¸ **ãƒœãƒˆãƒ«ãƒãƒƒã‚¯**
- ãƒ‡ã‚£ã‚¹ã‚¯åˆ¶ç´„: 500GB / 5GB = 100 Worktrees

**çµè«–**: æœ€å¤§4ã¤ã®Worktreeã‚’åŒæ™‚å®Ÿè¡Œå¯èƒ½

**å—å…¥æ¡ä»¶**:
- [ ] ã‚·ã‚¹ãƒ†ãƒ ãŒãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢åˆ¶ç´„ã‚’æ­£ç¢ºã«æ¤œå‡ºã™ã‚‹
- [ ] åˆ¶ç´„ã‚’è¶…ãˆã‚‹Worktreeä½œæˆãŒãƒ–ãƒ­ãƒƒã‚¯ã•ã‚Œã‚‹
- [ ] ãƒªã‚½ãƒ¼ã‚¹ä¸è¶³æ™‚ã«é©åˆ‡ãªã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒè¡¨ç¤ºã•ã‚Œã‚‹

### REQ-RES-2: Dynamic Scaling

**è©³ç´°ä»•æ§˜**:

```rust
// crates/miyabi-scheduler/src/dynamic_scaling.rs
pub struct DynamicScaler {
    resource_monitor: ResourceMonitor,
    current_parallelism: Arc<Mutex<usize>>,
    max_parallelism: usize,
}

impl DynamicScaler {
    pub async fn adjust_parallelism(&self) -> usize {
        let usage = self.resource_monitor.get_current_usage().await;
        let mut parallelism = self.current_parallelism.lock().await;

        // ã‚¹ã‚±ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³æ¡ä»¶
        if usage.memory_percent > 90.0 || usage.cpu_percent > 95.0 || usage.disk_percent > 85.0 {
            *parallelism = (*parallelism - 1).max(1);
            tracing::warn!(
                "Scaling down to {} due to resource pressure: mem={:.1}%, cpu={:.1}%, disk={:.1}%",
                *parallelism, usage.memory_percent, usage.cpu_percent, usage.disk_percent
            );
        }
        // ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—æ¡ä»¶
        else if usage.memory_percent < 70.0 && usage.cpu_percent < 75.0 && usage.disk_percent < 70.0 {
            *parallelism = (*parallelism + 1).min(self.max_parallelism);
            tracing::info!("Scaling up to {}", *parallelism);
        }

        *parallelism
    }

    pub async fn monitor_loop(&self) {
        let mut interval = tokio::time::interval(Duration::from_secs(10));
        loop {
            interval.tick().await;
            self.adjust_parallelism().await;
        }
    }
}
```

**å—å…¥æ¡ä»¶**:
- [ ] 10ç§’ã”ã¨ã«ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨ç‡ã‚’ç›£è¦–
- [ ] ãƒ¡ãƒ¢ãƒª90%è¶…éæ™‚ã«ä¸¦åˆ—åº¦ã‚’å‰Šæ¸›
- [ ] CPU95%è¶…éæ™‚ã«ä¸¦åˆ—åº¦ã‚’å‰Šæ¸›
- [ ] ãƒªã‚½ãƒ¼ã‚¹ã«ä½™è£•ãŒã‚ã‚‹æ™‚ã«ä¸¦åˆ—åº¦ã‚’å¢—åŠ 

### REQ-RES-3: LLM Rate Limiting

**è©³ç´°ä»•æ§˜**:

```rust
// crates/miyabi-llm/src/rate_limiter.rs
pub struct RateLimiter {
    requests_per_minute: usize,        // 50
    tokens_per_minute: usize,          // 40,000
    request_history: Arc<Mutex<VecDeque<Instant>>>,
    token_history: Arc<Mutex<VecDeque<(Instant, usize)>>>,
}

impl RateLimiter {
    pub async fn acquire_permit(&self, estimated_tokens: usize) -> Result<()> {
        loop {
            let now = Instant::now();
            let one_minute_ago = now - Duration::from_secs(60);

            // å¤ã„ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã‚’å‰Šé™¤
            {
                let mut requests = self.request_history.lock().await;
                while requests.front().map_or(false, |t| *t < one_minute_ago) {
                    requests.pop_front();
                }

                let mut tokens = self.token_history.lock().await;
                while tokens.front().map_or(false, |(t, _)| *t < one_minute_ago) {
                    tokens.pop_front();
                }
            }

            // ç¾åœ¨ã®ä½¿ç”¨çŠ¶æ³ã‚’ç¢ºèª
            let current_requests = self.request_history.lock().await.len();
            let current_tokens: usize = self.token_history.lock().await
                .iter()
                .map(|(_, t)| t)
                .sum();

            // åˆ¶é™å†…ã§ã‚ã‚Œã°è¨±å¯
            if current_requests < self.requests_per_minute
                && current_tokens + estimated_tokens < self.tokens_per_minute
            {
                self.request_history.lock().await.push_back(now);
                self.token_history.lock().await.push_back((now, estimated_tokens));
                return Ok(());
            }

            // åˆ¶é™è¶…éã®å ´åˆã¯å¾…æ©Ÿ
            tokio::time::sleep(Duration::from_millis(100)).await;
        }
    }
}
```

**å—å…¥æ¡ä»¶**:
- [ ] 1åˆ†é–“ã«50ãƒªã‚¯ã‚¨ã‚¹ãƒˆã¾ã§åˆ¶é™
- [ ] 1åˆ†é–“ã«40,000ãƒˆãƒ¼ã‚¯ãƒ³ã¾ã§åˆ¶é™
- [ ] åˆ¶é™è¶…éæ™‚ã«è‡ªå‹•çš„ã«å¾…æ©Ÿ
- [ ] ã‚¹ãƒ©ã‚¤ãƒ‡ã‚£ãƒ³ã‚°ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã§æ­£ç¢ºã«ç®¡ç†

---

## ğŸ’¾ Phase 3: State Persistence and Recovery

### REQ-PER-1: Database Schema

**è©³ç´°ä»•æ§˜**:

```sql
-- schema/miyabi.sql
CREATE TABLE execution_runs (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    issue_number INTEGER NOT NULL,
    status TEXT NOT NULL, -- 'running', 'completed', 'failed', 'interrupted'
    started_at TIMESTAMP NOT NULL,
    completed_at TIMESTAMP,
    total_cost_usd REAL DEFAULT 0.0,
    winning_world_id TEXT,
    final_score REAL
);

CREATE TABLE task_executions (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    run_id INTEGER NOT NULL,
    task_name TEXT NOT NULL,
    status TEXT NOT NULL,
    started_at TIMESTAMP NOT NULL,
    completed_at TIMESTAMP,
    FOREIGN KEY (run_id) REFERENCES execution_runs(id)
);

CREATE TABLE world_executions (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    task_id INTEGER NOT NULL,
    world_id TEXT NOT NULL, -- 'Alpha', 'Beta', 'Gamma', 'Delta', 'Epsilon'
    worktree_path TEXT NOT NULL,
    branch_name TEXT NOT NULL,
    status TEXT NOT NULL, -- 'running', 'completed', 'failed', 'terminated'
    started_at TIMESTAMP NOT NULL,
    completed_at TIMESTAMP,
    evaluation_score REAL,
    cost_usd REAL DEFAULT 0.0,
    FOREIGN KEY (task_id) REFERENCES task_executions(id)
);

CREATE TABLE checkpoints (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    run_id INTEGER NOT NULL,
    checkpoint_type TEXT NOT NULL, -- 'worktree_created', 'worlds_spawned', 'world_completed', 'evaluation_done', 'merge_ready'
    world_id TEXT,
    data JSON NOT NULL, -- ä»»æ„ã®çŠ¶æ…‹ãƒ‡ãƒ¼ã‚¿
    created_at TIMESTAMP NOT NULL,
    FOREIGN KEY (run_id) REFERENCES execution_runs(id)
);

CREATE TABLE worktrees (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    world_id TEXT NOT NULL,
    path TEXT NOT NULL,
    branch TEXT NOT NULL,
    created_at TIMESTAMP NOT NULL,
    last_accessed_at TIMESTAMP NOT NULL,
    is_orphaned BOOLEAN DEFAULT 0
);

CREATE INDEX idx_checkpoints_run_id ON checkpoints(run_id);
CREATE INDEX idx_checkpoints_type ON checkpoints(checkpoint_type);
CREATE INDEX idx_worktrees_last_accessed ON worktrees(last_accessed_at);
```

**å—å…¥æ¡ä»¶**:
- [ ] SQLiteãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒæ­£å¸¸ã«ä½œæˆã•ã‚Œã‚‹
- [ ] å…¨ãƒ†ãƒ¼ãƒ–ãƒ«ãŒå®šç¾©é€šã‚Šã«ä½œæˆã•ã‚Œã‚‹
- [ ] ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒé©åˆ‡ã«è¨­å®šã•ã‚Œã‚‹

### REQ-PER-2: Checkpoint System

**è©³ç´°ä»•æ§˜**:

```rust
// crates/miyabi-persistence/src/checkpoint.rs
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum CheckpointType {
    WorktreeCreated {
        world_id: WorldId,
        path: PathBuf,
        branch: String,
    },
    WorldsSpawned {
        task_id: i64,
        world_ids: Vec<WorldId>,
    },
    WorldCompleted {
        world_id: WorldId,
        score: f64,
        artifacts: Vec<PathBuf>,
    },
    EvaluationDone {
        winning_world: WorldId,
        all_scores: HashMap<WorldId, f64>,
    },
    MergeReady {
        winning_world: WorldId,
        pr_number: Option<u64>,
    },
}

pub struct CheckpointManager {
    db: Arc<SqlitePool>,
    interval: Duration, // 5åˆ†
}

impl CheckpointManager {
    pub async fn save_checkpoint(
        &self,
        run_id: i64,
        checkpoint: CheckpointType,
    ) -> Result<()> {
        let data = serde_json::to_string(&checkpoint)?;
        let checkpoint_type_str = checkpoint.type_name();
        let world_id = checkpoint.world_id();

        sqlx::query!(
            "INSERT INTO checkpoints (run_id, checkpoint_type, world_id, data, created_at)
             VALUES (?, ?, ?, ?, ?)",
            run_id,
            checkpoint_type_str,
            world_id,
            data,
            Utc::now()
        )
        .execute(&*self.db)
        .await?;

        Ok(())
    }

    pub async fn get_latest_checkpoint(
        &self,
        run_id: i64,
    ) -> Result<Option<CheckpointType>> {
        let row = sqlx::query!(
            "SELECT data FROM checkpoints
             WHERE run_id = ?
             ORDER BY created_at DESC
             LIMIT 1",
            run_id
        )
        .fetch_optional(&*self.db)
        .await?;

        if let Some(row) = row {
            Ok(Some(serde_json::from_str(&row.data)?))
        } else {
            Ok(None)
        }
    }

    pub async fn auto_checkpoint_loop(&self, run_id: i64) {
        let mut interval = tokio::time::interval(self.interval);
        loop {
            interval.tick().await;
            // ç¾åœ¨ã®çŠ¶æ…‹ã‚’è‡ªå‹•ä¿å­˜
            if let Err(e) = self.checkpoint_current_state(run_id).await {
                tracing::error!("Auto checkpoint failed: {}", e);
            }
        }
    }
}
```

**å—å…¥æ¡ä»¶**:
- [ ] 5åˆ†ã”ã¨ã«è‡ªå‹•çš„ã«ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãŒä¿å­˜ã•ã‚Œã‚‹
- [ ] 5ç¨®é¡ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚¿ã‚¤ãƒ—ãŒæ­£ã—ãä¿å­˜ã•ã‚Œã‚‹
- [ ] ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰ã®å¾©å…ƒãŒæ­£å¸¸ã«å‹•ä½œã™ã‚‹

### REQ-PER-3: Recovery System

**è©³ç´°ä»•æ§˜**:

```rust
// crates/miyabi-recovery/src/lib.rs
pub struct RecoveryManager {
    db: Arc<SqlitePool>,
    checkpoint_manager: Arc<CheckpointManager>,
}

impl RecoveryManager {
    pub async fn detect_interrupted_runs(&self) -> Result<Vec<i64>> {
        let rows = sqlx::query!(
            "SELECT id FROM execution_runs
             WHERE status = 'running'
             AND started_at < datetime('now', '-5 minutes')"
        )
        .fetch_all(&*self.db)
        .await?;

        Ok(rows.into_iter().map(|r| r.id).collect())
    }

    pub async fn resume_from_checkpoint(&self, run_id: i64) -> Result<()> {
        tracing::info!("Resuming run {} from checkpoint", run_id);

        let checkpoint = self.checkpoint_manager
            .get_latest_checkpoint(run_id)
            .await?
            .ok_or_else(|| anyhow!("No checkpoint found for run {}", run_id))?;

        match checkpoint {
            CheckpointType::WorktreeCreated { world_id, path, branch } => {
                // Worktreeå†æ¤œè¨¼
                self.verify_worktree(&path, &branch).await?;
                // Worldå®Ÿè¡Œã‚’å†é–‹
                self.resume_world_execution(run_id, world_id).await?;
            }
            CheckpointType::WorldsSpawned { task_id, world_ids } => {
                // å„Worldã®çŠ¶æ…‹ã‚’ç¢ºèª
                for world_id in world_ids {
                    self.check_world_status(task_id, world_id).await?;
                }
            }
            CheckpointType::WorldCompleted { world_id, .. } => {
                // ä»–ã®Worldã®å®Œäº†ã‚’å¾…ã¤
                self.wait_for_remaining_worlds(run_id).await?;
            }
            CheckpointType::EvaluationDone { winning_world, .. } => {
                // ãƒãƒ¼ã‚¸å‡¦ç†ã‚’å†é–‹
                self.resume_merge_process(run_id, winning_world).await?;
            }
            CheckpointType::MergeReady { winning_world, pr_number } => {
                // PRä½œæˆã¾ãŸã¯ãƒãƒ¼ã‚¸ã‚’å®Œäº†
                self.complete_merge(run_id, winning_world, pr_number).await?;
            }
        }

        Ok(())
    }
}
```

**å—å…¥æ¡ä»¶**:
- [ ] èµ·å‹•æ™‚ã«ä¸­æ–­ã•ã‚ŒãŸã‚¿ã‚¹ã‚¯ãŒè‡ªå‹•æ¤œå‡ºã•ã‚Œã‚‹
- [ ] æœ€æ–°ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰æ­£å¸¸ã«å¾©å…ƒã•ã‚Œã‚‹
- [ ] å¾©å…ƒå¾Œã®å®Ÿè¡ŒãŒæ­£ã—ãç¶™ç¶šã•ã‚Œã‚‹

### REQ-PER-4: Garbage Collection

**è©³ç´°ä»•æ§˜**:

```rust
// crates/miyabi-gc/src/lib.rs
pub struct GarbageCollector {
    db: Arc<SqlitePool>,
    worktree_manager: Arc<WorktreeManager>,
    worktree_lifetime: Duration, // 24æ™‚é–“
}

impl GarbageCollector {
    pub async fn collect_orphaned_worktrees(&self) -> Result<usize> {
        let threshold = Utc::now() - chrono::Duration::hours(24);

        let rows = sqlx::query!(
            "SELECT id, world_id, path, branch
             FROM worktrees
             WHERE last_accessed_at < ?
             AND is_orphaned = 0",
            threshold
        )
        .fetch_all(&*self.db)
        .await?;

        let mut cleaned = 0;
        for row in rows {
            tracing::info!("Cleaning up orphaned worktree: {:?}", row.path);

            // Worktreeå‰Šé™¤
            if let Err(e) = self.worktree_manager.cleanup_worktree_by_path(&row.path).await {
                tracing::error!("Failed to cleanup worktree {}: {}", row.path, e);
                continue;
            }

            // DBã‹ã‚‰å‰Šé™¤
            sqlx::query!("DELETE FROM worktrees WHERE id = ?", row.id)
                .execute(&*self.db)
                .await?;

            cleaned += 1;
        }

        Ok(cleaned)
    }

    pub async fn gc_loop(&self) {
        let mut interval = tokio::time::interval(Duration::from_secs(3600)); // 1æ™‚é–“
        loop {
            interval.tick().await;
            match self.collect_orphaned_worktrees().await {
                Ok(count) if count > 0 => {
                    tracing::info!("Garbage collected {} orphaned worktrees", count);
                }
                Err(e) => {
                    tracing::error!("Garbage collection failed: {}", e);
                }
                _ => {}
            }
        }
    }
}
```

**å—å…¥æ¡ä»¶**:
- [ ] 24æ™‚é–“ã‚¢ã‚¯ã‚»ã‚¹ã•ã‚Œã¦ã„ãªã„WorktreeãŒå‰Šé™¤ã•ã‚Œã‚‹
- [ ] 1æ™‚é–“ã”ã¨ã«GCãŒè‡ªå‹•å®Ÿè¡Œã•ã‚Œã‚‹
- [ ] GCå®Ÿè¡Œãƒ­ã‚°ãŒé©åˆ‡ã«è¨˜éŒ²ã•ã‚Œã‚‹

---

## ğŸ” Phase 4: Security Model

### REQ-SEC-1: Threat Model

**è©³ç´°ä»•æ§˜**:

```rust
// crates/miyabi-security/src/threat_model.rs
#[derive(Debug, Clone, Copy, PartialEq, Eq, PartialOrd, Ord)]
pub enum ThreatSeverity {
    Critical, // å³åº§ã«åœæ­¢
    High,     // å®Ÿè¡Œãƒ–ãƒ­ãƒƒã‚¯
    Medium,   // è­¦å‘Š
    Low,      // ãƒ­ã‚°ã®ã¿
}

#[derive(Debug, Clone)]
pub enum ThreatType {
    MaliciousCodeGeneration {
        pattern: String,
        severity: ThreatSeverity,
    },
    UnsafeRustUsage {
        location: String,
        severity: ThreatSeverity,
    },
    SecretLeakage {
        secret_type: SecretType,
        severity: ThreatSeverity,
    },
    UnauthorizedNetworkAccess {
        destination: String,
        severity: ThreatSeverity,
    },
    FileSystemAttack {
        target_path: PathBuf,
        severity: ThreatSeverity,
    },
}

#[derive(Debug, Clone, Copy)]
pub enum SecretType {
    ApiKey,
    Password,
    PrivateKey,
    Token,
    Certificate,
}
```

**å—å…¥æ¡ä»¶**:
- [ ] å…¨ã¦ã®è„…å¨ã‚¿ã‚¤ãƒ—ãŒå®šç¾©ã•ã‚Œã¦ã„ã‚‹
- [ ] è„…å¨ã®é‡å¤§åº¦ãŒé©åˆ‡ã«è¨­å®šã•ã‚Œã¦ã„ã‚‹
- [ ] Criticalè„…å¨æ¤œå‡ºæ™‚ã«å³åº§ã«åœæ­¢ã™ã‚‹

### REQ-SEC-2: Static Analysis

**è©³ç´°ä»•æ§˜**:

```rust
// crates/miyabi-security/src/static_analysis.rs
pub struct StaticAnalyzer {
    unsafe_detector: UnsafeDetector,
    dependency_checker: DependencyChecker,
    secret_scanner: SecretScanner,
    geiger_runner: GeigerRunner,
    semgrep_runner: SemgrepRunner,
}

impl StaticAnalyzer {
    pub async fn analyze_generated_code(
        &self,
        code: &str,
        world_id: WorldId,
    ) -> Result<SecurityReport> {
        let mut report = SecurityReport::default();

        // 1. Unsafe Rustæ¤œå‡º
        report.unsafe_blocks = self.unsafe_detector.scan(code)?;

        // 2. ä¾å­˜é–¢ä¿‚ãƒã‚§ãƒƒã‚¯
        report.external_dependencies = self.dependency_checker.check_cargo_toml(code)?;

        // 3. ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆæ¼æ´©æ¤œå‡º
        report.leaked_secrets = self.secret_scanner.scan(code)?;

        // 4. cargo-geiger (æ”¾å°„ç·šã‚¹ã‚³ã‚¢)
        report.radiation_score = self.geiger_runner.run().await?;

        // 5. Semgrepå®Ÿè¡Œ
        report.semgrep_findings = self.semgrep_runner.run(code).await?;

        // ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«è¨ˆç®—
        report.risk_level = self.calculate_risk_level(&report);

        // Highä»¥ä¸Šã®å ´åˆã¯å®Ÿè¡Œãƒ–ãƒ­ãƒƒã‚¯
        if report.risk_level >= RiskLevel::High {
            return Err(SecurityError::HighRiskCodeDetected { report }.into());
        }

        Ok(report)
    }

    fn calculate_risk_level(&self, report: &SecurityReport) -> RiskLevel {
        let mut score = 0;

        // Unsafeãƒ–ãƒ­ãƒƒã‚¯
        score += report.unsafe_blocks.len() * 10;

        // å¤–éƒ¨ä¾å­˜ (æœªæ¤œè¨¼)
        score += report.external_dependencies.iter()
            .filter(|d| !d.is_trusted)
            .count() * 5;

        // ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆæ¼æ´©
        score += report.leaked_secrets.len() * 50;

        // Geigeræ”¾å°„ç·šã‚¹ã‚³ã‚¢
        if report.radiation_score > 80.0 {
            score += 30;
        }

        // Semgrep findings
        score += report.semgrep_findings.len() * 8;

        match score {
            0..=20 => RiskLevel::Low,
            21..=50 => RiskLevel::Medium,
            51..=100 => RiskLevel::High,
            _ => RiskLevel::Critical,
        }
    }
}
```

**å—å…¥æ¡ä»¶**:
- [ ] 5ç¨®é¡ã®é™çš„è§£æãŒå®Ÿè¡Œã•ã‚Œã‚‹
- [ ] Unsafe Rustä½¿ç”¨ç®‡æ‰€ãŒæ¤œå‡ºã•ã‚Œã‚‹
- [ ] ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆæ¼æ´©ãŒæ¤œå‡ºã•ã‚Œã‚‹
- [ ] ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«ãŒæ­£ç¢ºã«è¨ˆç®—ã•ã‚Œã‚‹
- [ ] Highä»¥ä¸Šã®ãƒªã‚¹ã‚¯ã§å®Ÿè¡ŒãŒãƒ–ãƒ­ãƒƒã‚¯ã•ã‚Œã‚‹

### REQ-SEC-3: Container Isolation

**è©³ç´°ä»•æ§˜**:

```rust
// crates/miyabi-security/src/isolation.rs
pub struct IsolationManager {
    strategy: IsolationStrategy,
}

#[derive(Debug, Clone)]
pub enum IsolationStrategy {
    Docker {
        image: String,
        network: NetworkMode,
        cpu_limit: f64,
        memory_limit: String,
        read_only_fs: bool,
    },
    Process {
        chroot: bool,
        namespace: bool,
    },
    None, // é–‹ç™ºæ™‚ã®ã¿
}

impl Default for IsolationStrategy {
    fn default() -> Self {
        Self::Docker {
            image: "rust:1.75".to_string(),
            network: NetworkMode::None,
            cpu_limit: 2.0,
            memory_limit: "2g".to_string(),
            read_only_fs: true,
        }
    }
}

impl IsolationManager {
    pub async fn execute_in_container(
        &self,
        world_id: WorldId,
        command: &str,
        worktree_path: &Path,
    ) -> Result<Output> {
        match &self.strategy {
            IsolationStrategy::Docker {
                image, network, cpu_limit, memory_limit, read_only_fs, ..
            } => {
                let mut cmd = Command::new("docker");
                cmd.args([
                    "run",
                    "--rm",
                    "--cpus", &cpu_limit.to_string(),
                    "--memory", memory_limit,
                    "--network", network.as_str(),
                    "-v", &format!("{}:/workspace", worktree_path.display()),
                    "-w", "/workspace",
                ]);

                if *read_only_fs {
                    cmd.arg("--read-only");
                }

                cmd.arg(image)
                   .arg("sh")
                   .arg("-c")
                   .arg(command);

                let output = cmd.output().await?;
                Ok(output)
            }
            IsolationStrategy::Process { .. } => {
                // Processåˆ†é›¢å®Ÿè£…
                unimplemented!("Process isolation not yet implemented")
            }
            IsolationStrategy::None => {
                // åˆ†é›¢ãªã— (é–‹ç™ºæ™‚ã®ã¿)
                let output = Command::new("sh")
                    .arg("-c")
                    .arg(command)
                    .current_dir(worktree_path)
                    .output()
                    .await?;
                Ok(output)
            }
        }
    }
}

#[derive(Debug, Clone, Copy)]
pub enum NetworkMode {
    None,       // --network=none
    Host,       // --network=host
    Bridge,     // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
}

impl NetworkMode {
    fn as_str(&self) -> &str {
        match self {
            Self::None => "none",
            Self::Host => "host",
            Self::Bridge => "bridge",
        }
    }
}
```

**å—å…¥æ¡ä»¶**:
- [ ] ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§Dockeråˆ†é›¢ãŒæœ‰åŠ¹
- [ ] ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¢ã‚¯ã‚»ã‚¹ãŒç„¡åŠ¹åŒ–ã•ã‚Œã‚‹
- [ ] CPU/ãƒ¡ãƒ¢ãƒªåˆ¶é™ãŒé©ç”¨ã•ã‚Œã‚‹
- [ ] èª­ã¿å–ã‚Šå°‚ç”¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ãŒå¼·åˆ¶ã•ã‚Œã‚‹

### REQ-SEC-4: Runtime Monitoring

**è©³ç´°ä»•æ§˜**:

```rust
// crates/miyabi-security/src/runtime_monitor.rs
pub struct RuntimeMonitor {
    file_access_log: Arc<Mutex<Vec<FileAccessEvent>>>,
    network_access_log: Arc<Mutex<Vec<NetworkAccessEvent>>>,
    process_spawn_log: Arc<Mutex<Vec<ProcessSpawnEvent>>>,
}

#[derive(Debug, Clone)]
pub struct FileAccessEvent {
    pub world_id: WorldId,
    pub path: PathBuf,
    pub operation: FileOperation,
    pub timestamp: DateTime<Utc>,
    pub allowed: bool,
}

#[derive(Debug, Clone, Copy)]
pub enum FileOperation {
    Read,
    Write,
    Delete,
    Execute,
}

impl RuntimeMonitor {
    pub async fn log_file_access(
        &self,
        world_id: WorldId,
        path: PathBuf,
        operation: FileOperation,
    ) -> Result<()> {
        let allowed = self.is_file_access_allowed(&path, operation);

        let event = FileAccessEvent {
            world_id,
            path: path.clone(),
            operation,
            timestamp: Utc::now(),
            allowed,
        };

        self.file_access_log.lock().await.push(event.clone());

        if !allowed {
            return Err(SecurityError::UnauthorizedFileAccess { event }.into());
        }

        Ok(())
    }

    fn is_file_access_allowed(&self, path: &Path, operation: FileOperation) -> bool {
        // Worktreeå†…ã®ã¿è¨±å¯
        let worktree_pattern = Regex::new(r"^worktrees/").unwrap();
        if !worktree_pattern.is_match(&path.display().to_string()) {
            return false;
        }

        // å‰Šé™¤ã¯ç¦æ­¢
        if matches!(operation, FileOperation::Delete) {
            return false;
        }

        true
    }
}
```

**å—å…¥æ¡ä»¶**:
- [ ] å…¨ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ã‚¯ã‚»ã‚¹ãŒè¨˜éŒ²ã•ã‚Œã‚‹
- [ ] Worktreeå¤–ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ãŒãƒ–ãƒ­ãƒƒã‚¯ã•ã‚Œã‚‹
- [ ] ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤æ“ä½œãŒç¦æ­¢ã•ã‚Œã‚‹
- [ ] ãƒ­ã‚°ãŒé©åˆ‡ã«ä¿å­˜ã•ã‚Œã‚‹

---

## ğŸ“Š Phase 5: Observability

### REQ-OBS-1: Structured Logging

**è©³ç´°ä»•æ§˜**:

```rust
// crates/miyabi-observability/src/logging.rs
use tracing::{info, warn, error, instrument, Span};
use tracing_subscriber::{layer::SubscriberExt, util::SubscriberInitExt};

pub fn init_logging() -> Result<()> {
    tracing_subscriber::registry()
        .with(tracing_subscriber::fmt::layer()
            .json()
            .with_target(true)
            .with_level(true)
            .with_span_list(true)
        )
        .with(tracing_subscriber::EnvFilter::from_default_env())
        .init();

    Ok(())
}

pub struct IssueLogger {
    span: Span,
}

impl IssueLogger {
    #[instrument(skip(self), fields(issue_number = %issue_number))]
    pub fn new(issue_number: u64) -> Self {
        let span = tracing::info_span!("issue", issue_number = %issue_number);
        Self { span }
    }

    pub fn task_logger(&self, task_name: &str) -> TaskLogger {
        let _guard = self.span.enter();
        TaskLogger::new(task_name)
    }
}

pub struct TaskLogger {
    span: Span,
}

impl TaskLogger {
    #[instrument(skip(self), fields(task_name = %task_name))]
    pub fn new(task_name: &str) -> Self {
        let span = tracing::info_span!("task", task_name = %task_name);
        Self { span }
    }

    pub fn world_logger(&self, world_id: WorldId) -> WorldLogger {
        let _guard = self.span.enter();
        WorldLogger::new(world_id)
    }
}

pub struct WorldLogger {
    span: Span,
}

impl WorldLogger {
    #[instrument(skip(self), fields(world_id = ?world_id))]
    pub fn new(world_id: WorldId) -> Self {
        let span = tracing::info_span!("world", world_id = ?world_id);
        Self { span }
    }

    pub fn log_compilation(&self, success: bool, duration_ms: u64) {
        let _guard = self.span.enter();
        info!(
            compilation_success = success,
            duration_ms = duration_ms,
            "Compilation completed"
        );
    }

    pub fn log_test_results(&self, passed: usize, total: usize) {
        let _guard = self.span.enter();
        info!(
            tests_passed = passed,
            tests_total = total,
            pass_rate = (passed as f64 / total as f64),
            "Tests completed"
        );
    }
}
```

**ãƒ­ã‚°å‡ºåŠ›ä¾‹**:
```json
{
  "timestamp": "2025-10-25T12:34:56.789Z",
  "level": "INFO",
  "target": "miyabi_observability::logging",
  "spans": [
    {"name": "issue", "issue_number": 270},
    {"name": "task", "task_name": "implement_feature"},
    {"name": "world", "world_id": "Alpha"}
  ],
  "fields": {
    "compilation_success": true,
    "duration_ms": 4523
  },
  "message": "Compilation completed"
}
```

**å—å…¥æ¡ä»¶**:
- [ ] éšå±¤çš„ãªãƒ­ã‚°æ§‹é€ ãŒå®Ÿè£…ã•ã‚Œã‚‹ (Issue â†’ Task â†’ World)
- [ ] JSONå½¢å¼ã§ãƒ­ã‚°ãŒå‡ºåŠ›ã•ã‚Œã‚‹
- [ ] Spanã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãŒæ­£ã—ãä¼æ’­ã™ã‚‹

### REQ-OBS-2: Prometheus Metrics

**è©³ç´°ä»•æ§˜**:

```rust
// crates/miyabi-observability/src/metrics.rs
use prometheus::{
    Counter, Gauge, Histogram, HistogramOpts, Registry,
    register_counter, register_gauge, register_histogram,
};

lazy_static! {
    // Counters
    pub static ref ISSUES_TOTAL: Counter = register_counter!(
        "miyabi_issues_total",
        "Total number of issues processed"
    ).unwrap();

    pub static ref TASKS_TOTAL: Counter = register_counter!(
        "miyabi_tasks_total",
        "Total number of tasks executed"
    ).unwrap();

    pub static ref WORLDS_TOTAL: Counter = register_counter!(
        "miyabi_worlds_total",
        "Total number of worlds spawned"
    ).unwrap();

    pub static ref WORLDS_FAILED: Counter = register_counter!(
        "miyabi_worlds_failed_total",
        "Total number of failed worlds"
    ).unwrap();

    pub static ref LLM_REQUESTS_TOTAL: Counter = register_counter!(
        "miyabi_llm_requests_total",
        "Total number of LLM API requests"
    ).unwrap();

    pub static ref LLM_TOKENS_TOTAL: Counter = register_counter!(
        "miyabi_llm_tokens_total",
        "Total number of LLM tokens used"
    ).unwrap();

    // Gauges
    pub static ref ACTIVE_WORKTREES: Gauge = register_gauge!(
        "miyabi_active_worktrees",
        "Current number of active worktrees"
    ).unwrap();

    pub static ref MEMORY_USAGE_BYTES: Gauge = register_gauge!(
        "miyabi_memory_usage_bytes",
        "Current memory usage in bytes"
    ).unwrap();

    pub static ref CPU_USAGE_PERCENT: Gauge = register_gauge!(
        "miyabi_cpu_usage_percent",
        "Current CPU usage percentage"
    ).unwrap();

    pub static ref DISK_USAGE_BYTES: Gauge = register_gauge!(
        "miyabi_disk_usage_bytes",
        "Current disk usage in bytes"
    ).unwrap();

    // Histograms
    pub static ref TASK_DURATION: Histogram = register_histogram!(
        "miyabi_task_duration_seconds",
        "Task execution duration in seconds",
        vec![1.0, 5.0, 10.0, 30.0, 60.0, 120.0, 300.0, 600.0]
    ).unwrap();

    pub static ref WORLD_DURATION: Histogram = register_histogram!(
        "miyabi_world_duration_seconds",
        "World execution duration in seconds",
        vec![10.0, 30.0, 60.0, 120.0, 300.0, 600.0, 1200.0]
    ).unwrap();

    pub static ref LLM_LATENCY: Histogram = register_histogram!(
        "miyabi_llm_latency_seconds",
        "LLM API call latency in seconds",
        vec![0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 30.0]
    ).unwrap();

    pub static ref EVALUATION_SCORE: Histogram = register_histogram!(
        "miyabi_evaluation_score",
        "World evaluation scores (0-100)",
        vec![0.0, 20.0, 40.0, 60.0, 80.0, 90.0, 100.0]
    ).unwrap();
}

// ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆç”¨HTTPã‚µãƒ¼ãƒãƒ¼
pub async fn serve_metrics(port: u16) -> Result<()> {
    use warp::Filter;

    let metrics_route = warp::path("metrics").map(|| {
        use prometheus::Encoder;
        let encoder = prometheus::TextEncoder::new();
        let metric_families = prometheus::gather();
        let mut buffer = vec![];
        encoder.encode(&metric_families, &mut buffer).unwrap();
        String::from_utf8(buffer).unwrap()
    });

    warp::serve(metrics_route)
        .run(([0, 0, 0, 0], port))
        .await;

    Ok(())
}
```

**å—å…¥æ¡ä»¶**:
- [ ] 20å€‹ä»¥ä¸Šã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãŒå®šç¾©ã•ã‚Œã‚‹
- [ ] ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã€ã‚²ãƒ¼ã‚¸ã€ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ãŒæ­£ã—ãå®Ÿè£…ã•ã‚Œã‚‹
- [ ] `/metrics`ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã§ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãŒå…¬é–‹ã•ã‚Œã‚‹
- [ ] Prometheusã§ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å¯èƒ½

### REQ-OBS-3: Distributed Tracing

**è©³ç´°ä»•æ§˜**:

```rust
// crates/miyabi-observability/src/tracing_setup.rs
use opentelemetry::{
    global,
    sdk::{trace as sdktrace, Resource},
    KeyValue,
};
use opentelemetry_otlp::WithExportConfig;
use tracing_opentelemetry::OpenTelemetryLayer;

pub fn init_tracing(otlp_endpoint: &str) -> Result<()> {
    // OpenTelemetry OTLP exporter
    let tracer = opentelemetry_otlp::new_pipeline()
        .tracing()
        .with_exporter(
            opentelemetry_otlp::new_exporter()
                .tonic()
                .with_endpoint(otlp_endpoint)
        )
        .with_trace_config(
            sdktrace::config()
                .with_resource(Resource::new(vec![
                    KeyValue::new("service.name", "miyabi"),
                    KeyValue::new("service.version", env!("CARGO_PKG_VERSION")),
                ]))
        )
        .install_batch(opentelemetry::runtime::Tokio)?;

    // Tracing subscriber
    tracing_subscriber::registry()
        .with(tracing_subscriber::fmt::layer())
        .with(OpenTelemetryLayer::new(tracer))
        .with(tracing_subscriber::EnvFilter::from_default_env())
        .init();

    Ok(())
}

// ãƒˆãƒ¬ãƒ¼ã‚¹ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ä¼æ’­
#[instrument(skip(self))]
pub async fn execute_issue(&self, issue_number: u64) -> Result<()> {
    let span = Span::current();
    span.set_attribute(KeyValue::new("issue.number", issue_number as i64));

    // Taskå®Ÿè¡Œ
    for task in self.generate_tasks(issue_number).await? {
        self.execute_task(task).await?;
    }

    Ok(())
}

#[instrument(skip(self))]
pub async fn execute_task(&self, task: Task) -> Result<()> {
    let span = Span::current();
    span.set_attribute(KeyValue::new("task.name", task.name.clone()));

    // 5 Worldså®Ÿè¡Œ
    let mut handles = vec![];
    for world_id in WorldId::all() {
        let handle = self.execute_world(task.clone(), world_id);
        handles.push(handle);
    }

    // å…¨Worldå®Œäº†ã‚’å¾…æ©Ÿ
    let results = futures::future::join_all(handles).await;

    Ok(())
}

#[instrument(skip(self))]
pub async fn execute_world(&self, task: Task, world_id: WorldId) -> Result<WorldResult> {
    let span = Span::current();
    span.set_attribute(KeyValue::new("world.id", format!("{:?}", world_id)));

    // LLMå‘¼ã³å‡ºã—
    let code = self.llm_client.generate_code(&task).await?;

    // ã‚³ãƒ³ãƒ‘ã‚¤ãƒ« & ãƒ†ã‚¹ãƒˆ
    let result = self.compile_and_test(&code).await?;

    Ok(result)
}
```

**ãƒˆãƒ¬ãƒ¼ã‚¹éšå±¤**:
```
execute_issue (span_id: abc123)
â”œâ”€â”€ execute_task (span_id: def456, parent: abc123)
â”‚   â”œâ”€â”€ execute_world [Alpha] (span_id: ghi789, parent: def456)
â”‚   â”‚   â”œâ”€â”€ llm_generate_code (span_id: jkl012, parent: ghi789)
â”‚   â”‚   â””â”€â”€ compile_and_test (span_id: mno345, parent: ghi789)
â”‚   â”œâ”€â”€ execute_world [Beta] (span_id: pqr678, parent: def456)
â”‚   â”œâ”€â”€ execute_world [Gamma] (span_id: stu901, parent: def456)
â”‚   â”œâ”€â”€ execute_world [Delta] (span_id: vwx234, parent: def456)
â”‚   â””â”€â”€ execute_world [Epsilon] (span_id: yz0567, parent: def456)
â””â”€â”€ evaluate_worlds (span_id: abc890, parent: abc123)
```

**å—å…¥æ¡ä»¶**:
- [ ] OpenTelemetry OTLP exporterãŒå®Ÿè£…ã•ã‚Œã‚‹
- [ ] å…¨å®Ÿè¡Œéšå±¤ãŒãƒˆãƒ¬ãƒ¼ã‚¹ã•ã‚Œã‚‹ (Issue â†’ Task â†’ World)
- [ ] Spanã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãŒWorldé–“ã§æ­£ã—ãä¼æ’­ã™ã‚‹
- [ ] Jaegerã¾ãŸã¯Zipkinã§å¯è¦–åŒ–å¯èƒ½

### REQ-OBS-4: Grafana Dashboard

**è©³ç´°ä»•æ§˜**:

```json
{
  "dashboard": {
    "title": "Miyabi System Dashboard",
    "panels": [
      {
        "title": "Active Worktrees",
        "type": "graph",
        "targets": [{"expr": "miyabi_active_worktrees"}]
      },
      {
        "title": "World Success Rate",
        "type": "graph",
        "targets": [{
          "expr": "rate(miyabi_worlds_total[5m]) - rate(miyabi_worlds_failed_total[5m])"
        }]
      },
      {
        "title": "Task Duration (p50, p95, p99)",
        "type": "graph",
        "targets": [
          {"expr": "histogram_quantile(0.50, miyabi_task_duration_seconds_bucket)"},
          {"expr": "histogram_quantile(0.95, miyabi_task_duration_seconds_bucket)"},
          {"expr": "histogram_quantile(0.99, miyabi_task_duration_seconds_bucket)"}
        ]
      },
      {
        "title": "LLM API Latency",
        "type": "graph",
        "targets": [{"expr": "miyabi_llm_latency_seconds"}]
      },
      {
        "title": "Resource Usage",
        "type": "graph",
        "targets": [
          {"expr": "miyabi_memory_usage_bytes / 1024 / 1024 / 1024", "legend": "Memory (GB)"},
          {"expr": "miyabi_cpu_usage_percent", "legend": "CPU %"},
          {"expr": "miyabi_disk_usage_bytes / 1024 / 1024 / 1024", "legend": "Disk (GB)"}
        ]
      },
      {
        "title": "Evaluation Score Distribution",
        "type": "heatmap",
        "targets": [{"expr": "miyabi_evaluation_score_bucket"}]
      }
    ]
  }
}
```

**å—å…¥æ¡ä»¶**:
- [ ] Grafanaãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰å®šç¾©ãŒä½œæˆã•ã‚Œã‚‹
- [ ] 6å€‹ä»¥ä¸Šã®ãƒ‘ãƒãƒ«ãŒå®šç¾©ã•ã‚Œã‚‹
- [ ] ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨ç‡ã€æˆåŠŸç‡ã€ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãŒå¯è¦–åŒ–ã•ã‚Œã‚‹

---

## ğŸ’° Phase 6: Cost Optimization

### REQ-COST-1: Budget Management

**è©³ç´°ä»•æ§˜**:

```toml
# config/cost_limits.toml
[budget]
monthly_limit_usd = 1000.0
per_issue_target_usd = 5.0
max_issues_per_month = 200

[thresholds]
warning_percent = 75.0   # 750ãƒ‰ãƒ«åˆ°é”ã§è­¦å‘Š
pause_percent = 90.0     # 900ãƒ‰ãƒ«åˆ°é”ã§ä¸€æ™‚åœæ­¢
stop_percent = 100.0     # 1000ãƒ‰ãƒ«åˆ°é”ã§å®Œå…¨åœæ­¢

[alerts]
email = "admin@example.com"
slack_webhook = "https://hooks.slack.com/services/xxx"
```

**å—å…¥æ¡ä»¶**:
- [ ] æœˆé¡äºˆç®—ä¸Šé™ãŒè¨­å®šã•ã‚Œã‚‹
- [ ] Issueå˜ä¾¡ç›®æ¨™ãŒè¨­å®šã•ã‚Œã‚‹
- [ ] äºˆç®—ã—ãã„å€¤ãŒé©åˆ‡ã«è¨­å®šã•ã‚Œã‚‹

### REQ-COST-2: Cost Tracking

**ã‚³ã‚¹ãƒˆè¨ˆç®—å¼**:

```rust
impl CostTracker {
    fn calculate_cost(&self, model: &str, input_tokens: usize, output_tokens: usize) -> f64 {
        let pricing = match model {
            "gpt-4o" => (0.005, 0.015),           // $5/$15 per 1M tokens
            "gpt-4o-mini" => (0.00015, 0.0006),   // $0.15/$0.60 per 1M tokens
            "claude-3-5-sonnet" => (0.003, 0.015), // $3/$15 per 1M tokens
            "claude-3-haiku" => (0.00025, 0.00125), // $0.25/$1.25 per 1M tokens
            _ => (0.001, 0.002),                   // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        };

        (input_tokens as f64 / 1_000_000.0) * pricing.0 +
        (output_tokens as f64 / 1_000_000.0) * pricing.1
    }
}
```

**å—å…¥æ¡ä»¶**:
- [ ] å…¨LLMå‘¼ã³å‡ºã—ã§ã‚³ã‚¹ãƒˆãŒè¨˜éŒ²ã•ã‚Œã‚‹
- [ ] æœˆé–“ç´¯ç©ã‚³ã‚¹ãƒˆãŒè¿½è·¡ã•ã‚Œã‚‹
- [ ] ã‚³ã‚¹ãƒˆè¨ˆç®—ãŒæ­£ç¢ºã§ã‚ã‚‹

### REQ-COST-3: Early Termination

**è©³ç´°ä»•æ§˜**:

```rust
impl Default for EarlyTerminationPolicy {
    fn default() -> Self {
        Self {
            rules: vec![
                TerminationRule::TestFailureTimeout {
                    duration: Duration::from_secs(5 * 60),  // 5åˆ†
                    min_pass_rate: 0.0,                     // 0%
                },
                TerminationRule::CompilationFailureTimeout {
                    duration: Duration::from_secs(10 * 60), // 10åˆ†
                },
                TerminationRule::PerIssueCostExceeded {
                    threshold_usd: 10.0,                    // $10 (ç›®æ¨™ã®2å€)
                },
                TerminationRule::RepeatedFailurePattern {
                    max_repeats: 3,
                },
            ],
        }
    }
}
```

**å—å…¥æ¡ä»¶**:
- [ ] 5åˆ†ã§ãƒ†ã‚¹ãƒˆ0%ã®WorldãŒåœæ­¢ã•ã‚Œã‚‹
- [ ] 10åˆ†ã§ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«å¤±æ•—ã®WorldãŒåœæ­¢ã•ã‚Œã‚‹
- [ ] $10è¶…éæ™‚ã«å…¨WorldãŒåœæ­¢ã•ã‚Œã‚‹
- [ ] 3å›é€£ç¶šåŒä¸€ã‚¨ãƒ©ãƒ¼ã§åœæ­¢ã•ã‚Œã‚‹

### REQ-COST-4: Response Caching

**è©³ç´°ä»•æ§˜**:

```rust
pub struct LlmResponseCache {
    cache: Arc<Mutex<LruCache<CacheKey, CachedResponse>>>,
    capacity: usize, // 1000ã‚¨ãƒ³ãƒˆãƒªãƒ¼
    ttl: Duration,   // 7æ—¥é–“
}

#[derive(Hash, Eq, PartialEq)]
struct CacheKey {
    prompt_hash: String,      // SHA256(prompt)
    model: String,
    temperature: String,      // "0.7" (å°æ•°ç‚¹1æ¡)
}
```

**ã‚­ãƒ£ãƒƒã‚·ãƒ¥æˆ¦ç•¥**:
- å®¹é‡: 1000ã‚¨ãƒ³ãƒˆãƒªãƒ¼ (LRUæ–¹å¼)
- æœ‰åŠ¹æœŸé™: 7æ—¥é–“
- ã‚­ãƒ¼ã®æ­£è¦åŒ–: temperatureå°æ•°ç‚¹1æ¡ã«ä¸¸ã‚ã‚‹
- **ç›®æ¨™ãƒ’ãƒƒãƒˆç‡: 30%**

**å—å…¥æ¡ä»¶**:
- [ ] LRUã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒå®Ÿè£…ã•ã‚Œã‚‹
- [ ] 7æ—¥é–“ã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒæœŸé™åˆ‡ã‚Œã«ãªã‚‹
- [ ] ãƒ’ãƒƒãƒˆç‡ãŒè¿½è·¡ã•ã‚Œã‚‹
- [ ] ç›®æ¨™ãƒ’ãƒƒãƒˆç‡30%ã‚’é”æˆã™ã‚‹

### REQ-COST-5: Model Selection

**è©³ç´°ä»•æ§˜**:

```rust
impl Task {
    fn complexity(&self) -> TaskComplexity {
        // LOCã€ä¾å­˜æ•°ã€ãƒ†ã‚¹ãƒˆæ•°ã§åˆ¤å®š
        if self.estimated_loc < 50 && self.dependencies.len() < 3 {
            TaskComplexity::Simple
        } else if self.estimated_loc < 200 && self.dependencies.len() < 10 {
            TaskComplexity::Medium
        } else {
            TaskComplexity::Complex
        }
    }
}

impl ModelSelector {
    pub fn select_model_for_task(task: &Task) -> ModelConfig {
        match task.complexity() {
            TaskComplexity::Simple => ModelConfig {
                model: "gpt-4o-mini".to_string(),
                temperature: 0.5,
                max_tokens: 2000,
                // ã‚³ã‚¹ãƒˆ: ~$0.10/ã‚¿ã‚¹ã‚¯
            },
            TaskComplexity::Medium => ModelConfig {
                model: "gpt-4o".to_string(),
                temperature: 0.7,
                max_tokens: 4000,
                // ã‚³ã‚¹ãƒˆ: ~$1.00/ã‚¿ã‚¹ã‚¯
            },
            TaskComplexity::Complex => ModelConfig {
                model: "claude-3-5-sonnet".to_string(),
                temperature: 0.7,
                max_tokens: 8000,
                // ã‚³ã‚¹ãƒˆ: ~$2.50/ã‚¿ã‚¹ã‚¯
            },
        }
    }
}
```

**ã‚³ã‚¹ãƒˆæ¨å®š**:
```
1 Issue = 3 Tasks (å¹³å‡)
1 Task = 5 Worlds Ã— 2 LLM calls = 10 LLM calls

å†…è¨³:
- Simple Task (60%): $0.10 Ã— 10 Ã— 1.8 = $1.80
- Medium Task (30%): $1.00 Ã— 10 Ã— 0.9 = $9.00
- Complex Task (10%): $2.50 Ã— 10 Ã— 0.3 = $7.50

å¹³å‡: $4.53 âœ…
ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆ30%æƒ³å®š: $4.53 Ã— 0.7 = $3.17 âœ…âœ…
```

**å—å…¥æ¡ä»¶**:
- [ ] ã‚¿ã‚¹ã‚¯ã®è¤‡é›‘åº¦ãŒæ­£ã—ãè¨ˆç®—ã•ã‚Œã‚‹
- [ ] Simple/Medium/Complexã§ç•°ãªã‚‹ãƒ¢ãƒ‡ãƒ«ãŒé¸æŠã•ã‚Œã‚‹
- [ ] Issueå˜ä¾¡ãŒç›®æ¨™$5.00ä»¥å†…ã«åã¾ã‚‹

---

## ğŸ¯ Acceptance Criteria Summary

### ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã®å—å…¥æ¡ä»¶

1. **æ©Ÿèƒ½è¦ä»¶**:
   - [ ] GitHub Issueã‚’å…¥åŠ›ã¨ã—ã¦å—ã‘ä»˜ã‘ã‚‹
   - [ ] 5ã¤ã®Worlds (Î±, Î², Î³, Î´, Îµ) ã§ä¸¦åˆ—å®Ÿè¡Œã•ã‚Œã‚‹
   - [ ] å„WorldãŒç‹¬ç«‹ã—ãŸGit Worktreeã§å‹•ä½œã™ã‚‹
   - [ ] è©•ä¾¡ã‚¹ã‚³ã‚¢100ç‚¹æº€ç‚¹ã§æœ€è‰¯ã®Worldã‚’é¸æŠã™ã‚‹
   - [ ] å‹è€…ã®ã¿ãŒmainãƒ–ãƒ©ãƒ³ãƒã«ãƒãƒ¼ã‚¸ã•ã‚Œã‚‹

2. **å“è³ªè¦ä»¶**:
   - [ ] ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æˆåŠŸç‡ > 80%
   - [ ] ãƒ†ã‚¹ãƒˆåˆæ ¼ç‡ > 70%
   - [ ] Clippyè­¦å‘Šæ•° < 10
   - [ ] ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒªã‚¹ã‚¯ < High
   - [ ] è©•ä¾¡ã‚¹ã‚³ã‚¢å¹³å‡ > 70ç‚¹

3. **æ€§èƒ½è¦ä»¶**:
   - [ ] Issueå‡¦ç†æ™‚é–“ < 30åˆ† (å¹³å‡)
   - [ ] åŒæ™‚Worktreeæ•°: æœ€å¤§4å€‹
   - [ ] LLMãƒ¬ã‚¤ãƒ†ãƒ³ã‚· < 10ç§’ (p95)
   - [ ] ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ < 90%
   - [ ] CPUä½¿ç”¨ç‡ < 95%

4. **ä¿¡é ¼æ€§è¦ä»¶**:
   - [ ] 5åˆ†ã”ã¨ã«ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜
   - [ ] ã‚¯ãƒ©ãƒƒã‚·ãƒ¥å¾Œã®è‡ªå‹•å¾©æ—§
   - [ ] 24æ™‚é–“å¾Œã®å­¤å…Worktreeè‡ªå‹•å‰Šé™¤
   - [ ] ãƒªãƒˆãƒ©ã‚¤æˆåŠŸç‡ > 80%
   - [ ] éƒ¨åˆ†å¤±æ•—æ™‚ã®ç¶™ç¶šå®Ÿè¡Œ

5. **ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¦ä»¶**:
   - [ ] 4å±¤é˜²å¾¡ãŒå®Ÿè£…ã•ã‚Œã‚‹
   - [ ] é™çš„è§£æåˆæ ¼ç‡ 100%
   - [ ] ã‚³ãƒ³ãƒ†ãƒŠåˆ†é›¢ãŒãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæœ‰åŠ¹
   - [ ] ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ç›£è¦–ãŒå‹•ä½œ
   - [ ] ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆæ¼æ´©æ¤œå‡ºç‡ 100%

6. **ã‚³ã‚¹ãƒˆè¦ä»¶**:
   - [ ] æœˆé¡äºˆç®— $1000ä»¥å†…
   - [ ] Issueå˜ä¾¡ $5.00ä»¥å†…
   - [ ] ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡ > 30%
   - [ ] æ—©æœŸæ‰“ã¡åˆ‡ã‚ŠæˆåŠŸç‡ > 50%

7. **è¦³æ¸¬å¯èƒ½æ€§è¦ä»¶**:
   - [ ] æ§‹é€ åŒ–ãƒ­ã‚°ãŒJSONå½¢å¼ã§å‡ºåŠ›ã•ã‚Œã‚‹
   - [ ] 20å€‹ä»¥ä¸Šã®Prometheusãƒ¡ãƒˆãƒªã‚¯ã‚¹ãŒå…¬é–‹ã•ã‚Œã‚‹
   - [ ] OpenTelemetryãƒˆãƒ¬ãƒ¼ã‚¹ãŒæ­£å¸¸ã«å‹•ä½œã™ã‚‹
   - [ ] Grafanaãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ãŒè¡¨ç¤ºã•ã‚Œã‚‹

---

## ğŸ“¦ Deliverables

### Phase 1: Core Implementation (Week 1-2)
- [ ] `miyabi-types` crate: å…¨å‹å®šç¾©
- [ ] `miyabi-worktree` crate: Worktreeç®¡ç†
- [ ] `miyabi-core` crate: ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã€ãƒªã‚½ãƒ¼ã‚¹ç®¡ç†
- [ ] `miyabi-scheduler` crate: å‹•çš„ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°

### Phase 2: LLM Integration (Week 3)
- [ ] `miyabi-llm` crate: LLMæŠ½è±¡åŒ–å±¤ã€Rate Limiterã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥

### Phase 3: Persistence & Recovery (Week 4)
- [ ] `miyabi-persistence` crate: SQLiteæ°¸ç¶šåŒ–
- [ ] `miyabi-recovery` crate: å¾©æ—§ã‚·ã‚¹ãƒ†ãƒ 
- [ ] `miyabi-gc` crate: ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³

### Phase 4: Security (Week 5)
- [ ] `miyabi-security` crate: é™çš„è§£æã€åˆ†é›¢ã€ç›£è¦–

### Phase 5: Observability (Week 6)
- [ ] `miyabi-observability` crate: ãƒ­ã‚°ã€ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã€ãƒˆãƒ¬ãƒ¼ã‚¹
- [ ] Grafanaãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰å®šç¾©

### Phase 6: Cost Optimization (Week 7)
- [ ] `miyabi-cost` crate: ã‚³ã‚¹ãƒˆè¿½è·¡ã€æ—©æœŸæ‰“ã¡åˆ‡ã‚Š

### Phase 7: Integration & Testing (Week 8)
- [ ] çµ±åˆãƒ†ã‚¹ãƒˆ
- [ ] ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ãƒ†ã‚¹ãƒˆ
- [ ] ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆ

---

## ğŸ“š References

- [ENTITY_RELATION_MODEL.md](ENTITY_RELATION_MODEL.md) - Entityå®šç¾©ã¨é–¢ä¿‚æ€§
- [LABEL_SYSTEM_GUIDE.md](LABEL_SYSTEM_GUIDE.md) - Labelä½“ç³»
- [AGENT_CHARACTERS.md](../.claude/agents/AGENT_CHARACTERS.md) - Agentä»•æ§˜
- [MCP_INTEGRATION_PROTOCOL.md](../.claude/MCP_INTEGRATION_PROTOCOL.md) - MCPçµ±åˆ
- [BENCHMARK_IMPLEMENTATION_CHECKLIST.md](../.claude/BENCHMARK_IMPLEMENTATION_CHECKLIST.md) - ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè£…

---

**Document Status**: âœ… FINAL - Ready for Implementation
**Next Phase**: å®Ÿè£…ãƒ•ã‚§ãƒ¼ã‚ºé–‹å§‹ (Week 1)

**Approved by**: System Architect
**Date**: 2025-10-25

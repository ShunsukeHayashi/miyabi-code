#!/usr/bin/env python3
"""
ã‚·ãƒ³ãƒ—ãƒ«ãªã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ‡ãƒ¢
DMMä¸€èˆ¬ãƒšãƒ¼ã‚¸ï¼ˆå¹´é½¢ç¢ºèªãªã—ï¼‰ã‹ã‚‰æ–°ä½œæƒ…å ±ã‚’å–å¾—

Usage:
    python3 simple_scraper_demo.py
"""

import json
from datetime import datetime
from pathlib import Path
from time import sleep

try:
    import requests
    from bs4 import BeautifulSoup
except ImportError:
    print("âŒ å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
    print("   pip3 install requests beautifulsoup4")
    exit(1)


def scrape_dmm_general():
    """DMMä¸€èˆ¬ã‚µã‚¤ãƒˆã‹ã‚‰æ–°ä½œæƒ…å ±ã‚’å–å¾—ï¼ˆãƒ‡ãƒ¢ï¼‰"""

    # ä¸€èˆ¬å‘ã‘DMMã®æ–°ä½œãƒšãƒ¼ã‚¸ï¼ˆå¹´é½¢ç¢ºèªãªã—ï¼‰
    url = "https://www.dmm.com/digital/-/new-release/=/type=rental/"

    print(f"ğŸ” ãƒšãƒ¼ã‚¸ã‚’å–å¾—ä¸­: {url}")

    headers = {
        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36",
    }

    try:
        response = requests.get(url, headers=headers, timeout=30)
        response.raise_for_status()

        soup = BeautifulSoup(response.content, "html.parser")

        # ã‚¿ã‚¤ãƒˆãƒ«å–å¾—
        title = soup.find("title")
        print(f"âœ… ãƒšãƒ¼ã‚¸å–å¾—æˆåŠŸ: {title.text if title else 'ã‚¿ã‚¤ãƒˆãƒ«ä¸æ˜'}")

        # å•†å“ãƒªã‚¹ãƒˆã‚’æ¢ã™ï¼ˆå®Ÿéš›ã®HTMLæ§‹é€ ã«ä¾å­˜ï¼‰
        items = []

        # ä¸€èˆ¬çš„ãªDMMã®å•†å“ãƒªã‚¹ãƒˆæ§‹é€ ã‚’è©¦ã™
        product_list = soup.find("ul", class_="d-item") or soup.find("div", id="list")

        if product_list:
            product_items = product_list.find_all("li")[:10]  # æœ€åˆã®10ä»¶
            print(f"   â†’ {len(product_items)}ä»¶ã®å•†å“ã‚’ç™ºè¦‹")

            for idx, item in enumerate(product_items, 1):
                # ã‚¿ã‚¤ãƒˆãƒ«æŠ½å‡º
                title_elem = item.find("a")
                title_text = title_elem.get("title") if title_elem else "ä¸æ˜"
                link = title_elem.get("href") if title_elem else ""

                items.append({
                    "index": idx,
                    "title": title_text,
                    "url": f"https://www.dmm.com{link}" if link.startswith("/") else link,
                })

                print(f"   {idx}. {title_text[:50]}...")
        else:
            print("âš ï¸  å•†å“ãƒªã‚¹ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            print("   ãƒšãƒ¼ã‚¸æ§‹é€ :")
            # ãƒ‡ãƒãƒƒã‚°: ä¸»è¦ãªè¦ç´ ã‚’è¡¨ç¤º
            for tag in ["ul", "div", "section"]:
                elements = soup.find_all(tag, limit=5)
                for elem in elements:
                    classes = elem.get("class", [])
                    elem_id = elem.get("id", "")
                    print(f"     <{tag} class='{classes}' id='{elem_id}'>")

        return items

    except requests.RequestException as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        return []


def save_demo_result(items):
    """ãƒ‡ãƒ¢çµæœã‚’ä¿å­˜"""
    output_dir = Path("data/fanza")
    output_dir.mkdir(parents=True, exist_ok=True)

    output_file = output_dir / f"demo_scraping_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"

    with open(output_file, "w", encoding="utf-8") as f:
        f.write("# ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ‡ãƒ¢çµæœ\n\n")
        f.write(f"**å®Ÿè¡Œæ—¥æ™‚**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"**å–å¾—ä»¶æ•°**: {len(items)}ä»¶\n\n")
        f.write("---\n\n")

        for item in items:
            f.write(f"## {item['index']}. {item['title']}\n\n")
            f.write(f"- **URL**: {item['url']}\n\n")
            f.write("---\n\n")

    print(f"\nâœ… çµæœã‚’ä¿å­˜: {output_file}")
    return output_file


def main():
    print("ğŸ¬ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ‡ãƒ¢ã‚’é–‹å§‹ã—ã¾ã™")
    print("   å¯¾è±¡: DMMä¸€èˆ¬ã‚µã‚¤ãƒˆï¼ˆå¹´é½¢ç¢ºèªãªã—ï¼‰")
    print("")

    items = scrape_dmm_general()

    if items:
        output_file = save_demo_result(items)
        print(f"\nğŸ“Š å–å¾—ä»¶æ•°: {len(items)}")
        print("ğŸ‰ ãƒ‡ãƒ¢å®Œäº†ï¼")
        print(f"\nğŸ’¡ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
        print(f"   1. ç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèª: cat {output_file}")
        print(f"   2. å®Ÿéš›ã®FANZAãƒšãƒ¼ã‚¸ã«å¯¾å¿œã™ã‚‹ã«ã¯HTMLæ§‹é€ ã®è§£æãŒå¿…è¦ã§ã™")
    else:
        print("\nâŒ å•†å“æƒ…å ±ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
        print("   â†’ HTMLæ§‹é€ ãŒæƒ³å®šã¨ç•°ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")


if __name__ == "__main__":
    main()
